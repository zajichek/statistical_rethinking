<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Small Worlds and Large Worlds – A Journey Through Statistical Rethinking</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter3.html" rel="next">
<link href="./chapter1.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-ef32913bf35ef406ecb39361441a99c8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter2.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Small Worlds and Large Worlds</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">A Journey Through Statistical Rethinking</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Golem of Prague</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Small Worlds and Large Worlds</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Sampling the Imaginary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#unraveling-the-counting-process" id="toc-unraveling-the-counting-process" class="nav-link active" data-scroll-target="#unraveling-the-counting-process"><span class="header-section-number">2.1</span> Unraveling the counting process</a>
  <ul class="collapse">
  <li><a href="#first-the-likelihood" id="toc-first-the-likelihood" class="nav-link" data-scroll-target="#first-the-likelihood"><span class="header-section-number">2.1.1</span> First, the likelihood</a></li>
  <li><a href="#incorporating-prior-knowledge" id="toc-incorporating-prior-knowledge" class="nav-link" data-scroll-target="#incorporating-prior-knowledge"><span class="header-section-number">2.1.2</span> Incorporating prior knowledge</a></li>
  </ul></li>
  <li><a href="#building-a-model" id="toc-building-a-model" class="nav-link" data-scroll-target="#building-a-model"><span class="header-section-number">2.2</span> Building a model</a>
  <ul class="collapse">
  <li><a href="#updatingpriors" id="toc-updatingpriors" class="nav-link" data-scroll-target="#updatingpriors"><span class="header-section-number">2.2.1</span> Updating priors</a></li>
  <li><a href="#bayesian-models-need-no-data" id="toc-bayesian-models-need-no-data" class="nav-link" data-scroll-target="#bayesian-models-need-no-data"><span class="header-section-number">2.2.2</span> Bayesian models need no data</a></li>
  <li><a href="#tie-inferences-back-to-what-matters" id="toc-tie-inferences-back-to-what-matters" class="nav-link" data-scroll-target="#tie-inferences-back-to-what-matters"><span class="header-section-number">2.2.3</span> Tie inferences back to what matters</a></li>
  <li><a href="#is-bayesian-modeling-subjective" id="toc-is-bayesian-modeling-subjective" class="nav-link" data-scroll-target="#is-bayesian-modeling-subjective"><span class="header-section-number">2.2.4</span> Is Bayesian modeling subjective?</a></li>
  </ul></li>
  <li><a href="#making-your-model-work" id="toc-making-your-model-work" class="nav-link" data-scroll-target="#making-your-model-work"><span class="header-section-number">2.3</span> Making Your Model Work</a>
  <ul class="collapse">
  <li><a href="#grid-approximation" id="toc-grid-approximation" class="nav-link" data-scroll-target="#grid-approximation"><span class="header-section-number">2.3.1</span> Grid approximation</a></li>
  <li><a href="#quadratic-approximation" id="toc-quadratic-approximation" class="nav-link" data-scroll-target="#quadratic-approximation"><span class="header-section-number">2.3.2</span> Quadratic approximation</a></li>
  <li><a href="#markov-chain-monte-carlo-mcmc" id="toc-markov-chain-monte-carlo-mcmc" class="nav-link" data-scroll-target="#markov-chain-monte-carlo-mcmc"><span class="header-section-number">2.3.3</span> Markov chain Monte Carlo (MCMC)</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Small Worlds and Large Worlds</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>“Colombo [Christopher Columbus] made a prediction based upon his view that the world was small. But since he lived in a large world, aspects of the prediction were wrong. In his case, the error was lucky.” (19)</p>
</blockquote>
<p>All models are and will always be wrong, that’s why they are called models. The “small world” represented by the model can only hope to be reflective of “large world”, the actual environment in which the model, insights, and inference that come out of it are used (i.e., where the rubber meets the road).</p>
<section id="unraveling-the-counting-process" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="unraveling-the-counting-process"><span class="header-section-number">2.1</span> Unraveling the counting process</h2>
<p>The “garden of forking paths” idea is about stretching out the process for counting things. Often in statistics, we just use formulas, or integrals, or whatever other notation to think through logic in our heads. This fundamental, systematic approach to counting lets us see what’s really going on behind the scenes. Ultimately, this leads to a more intuitive understanding of what Bayesian modeling is (in McElreath’s words): <em>“really just counting and comparing of possibilities”</em> (20).</p>
<section id="first-the-likelihood" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="first-the-likelihood"><span class="header-section-number">2.1.1</span> First, the likelihood</h3>
<p>In the marble example, he starts by counting the number of ways a particular observed sequence of marble draws could have occurred <em>given</em> an assumed true state of the bag (i.e., a hypothesis, which he calls <em>conjecture</em>). Then proceeds to manually count (and draw) the possibilities–nothing fancy about it, just brute force. Once this count is obtained, the question becomes: <em>what is this collection of counts for all other possible states of the bag?</em>. This is getting at what Bayesian analysis fundamentally is: determining which state of the world is most likely given the evidence.</p>
<blockquote class="blockquote">
<p>“By comparing these counts, we have part of a solution for a way to rate the relative plausibility of each conjectured bag composition.” (23)</p>
</blockquote>
<p>The word <em>relative</em> foreshadows many implications in Bayesian analysis, such as the focus on priors and likelihoods (not the normalizing constant), the different approaches to getting at the same answer (counts, rates, etc.), and the focus of comparing possible hypotheses relative to one another (and the whole slate of possibilities).</p>
<section id="translating-to-familar-notation" class="level4" data-number="2.1.1.1">
<h4 data-number="2.1.1.1" class="anchored" data-anchor-id="translating-to-familar-notation"><span class="header-section-number">2.1.1.1</span> Translating to familar notation</h4>
<p>Since I come at this from the “traditional” statistical point of view, it’s helpful to reconcile the approach here with the way I would typically think about it. Namely, we have a bag with four (4) marbles in it, each one being white or blue. Based on a sample from the bag, we want to infer what make up of all marbles is. Thus, the unknown parameter can be thought of as <span class="math inline">\(p\)</span>, the proportion of marbles that are blue (or white if we wanted). So, <span class="math inline">\(p\)</span> can be one of five choices: <span class="math inline">\(p \in (0, .25, .5, .75, 1)\)</span>. On page 21 it was stated that <em>“a sequence of three marbles is pulled from the bag, one at a time, replacing the marble each time and shaking the bag before drawing another marble”</em>–so we are <em>assuming</em> that we are selecting randomly with replacement (as a side note, a key point is our assumption: <em>we are using our judgement that the sampling method (shaking randomly) is sufficient to assume random, independent draws, but this paradigm leaves the possibility to account for modeling steps where this assumption may not be valid).</em></p>
<p>If we take <span class="math inline">\(N=3\)</span> draws and <span class="math inline">\(X=2\)</span> is the number that were blue, then we can think of:</p>
<p><span class="math inline">\(X \sim Binomial(N=3, p)\)</span></p>
<p>And we get the following counts of possible ways to observe this sequence for each value of <span class="math inline">\(p\)</span>.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Possible values of p</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, .<span class="dv">25</span>, .<span class="dv">5</span>, .<span class="dv">75</span>, <span class="dv">1</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>marbles <span class="ot">&lt;-</span> <span class="fu">length</span>(p) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of samples</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Observed sequence (1 = blue, 0 = white)</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">sum</span>(X)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># How many ways could this happen for each p?</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>ways <span class="ot">&lt;-</span> (marbles <span class="sc">*</span> p)<span class="sc">^</span>X <span class="sc">*</span> (marbles <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>p))<span class="sc">^</span>(N<span class="sc">-</span>X)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, ways, <span class="at">posterior_probability =</span> ways <span class="sc">/</span> <span class="fu">sum</span>(ways))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>        p ways posterior_probability
[1,] 0.00    0                  0.00
[2,] 0.25    3                  0.15
[3,] 0.50    8                  0.40
[4,] 0.75    9                  0.45
[5,] 1.00    0                  0.00</code></pre>
</div>
</div>
<p>This matches what is in the book on page 23. Why? Well because there is a finite number of marbles, and we are re-scaling to be in absolute terms relative to that, instead of being in rate terms. The point is that we can think of the counting process in absolute magnitude (counts), relative (probabilities), or even likelihoods (basically, non-normalized probabilities). They will all produce the <em>same</em> posterior probability suggesting that the bag most likely has 3 blue marbles, because our calculation is <em>relative</em> to span of possible hypotheses (conjectures).</p>
<p>Here we use the full <a href="https://en.wikipedia.org/wiki/Binomial_distribution">binomial</a> distribution for our calculations:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute traditional binomial probabilities</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>binom_probs <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="at">x =</span> X, <span class="at">size =</span> N, <span class="at">prob =</span> p)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, binom_probs, <span class="at">posterior_probability =</span> binom_probs <span class="sc">/</span> <span class="fu">sum</span>(binom_probs))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>        p binom_probs posterior_probability
[1,] 0.00    0.000000                  0.00
[2,] 0.25    0.140625                  0.15
[3,] 0.50    0.375000                  0.40
[4,] 0.75    0.421875                  0.45
[5,] 1.00    0.000000                  0.00</code></pre>
</div>
</div>
<p>Now we could even do it without it being normalized (i.e., we don’t care if it adds to 1):</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute unnormalized probabilities</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>unnorm_probs <span class="ot">&lt;-</span> p<span class="sc">^</span>X <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">^</span>(N<span class="sc">-</span>X)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, unnorm_probs, <span class="at">posterior_probability =</span> unnorm_probs <span class="sc">/</span> <span class="fu">sum</span>(unnorm_probs))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>        p unnorm_probs posterior_probability
[1,] 0.00     0.000000                  0.00
[2,] 0.25     0.046875                  0.15
[3,] 0.50     0.125000                  0.40
[4,] 0.75     0.140625                  0.45
[5,] 1.00     0.000000                  0.00</code></pre>
</div>
</div>
<p>They all lead to same <em>relative</em> posterior probability (3 blue marbles).</p>
<p>One key caveat here that comes next: these results assume that each value of <span class="math inline">\(p\)</span> is equally likely. But as he points out:</p>
<blockquote class="blockquote">
<p>“We may have additional information about the relative plausibility of each conjecture. This information could arise from knowledge of how the contens of the bag were generated.” (25)</p>
</blockquote>
<p>This gets at the idea of a <em>prior</em> distribution. We may know something about how the bag was arranged, such that we have an inkling that a particular value of <span class="math inline">\(p\)</span> is more likely to be true than the rest. In that case, what we have done above doesn’t work.</p>
</section>
</section>
<section id="incorporating-prior-knowledge" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="incorporating-prior-knowledge"><span class="header-section-number">2.1.2</span> Incorporating prior knowledge</h3>
<p>Since we’ve just established the number of ways to observe the original sequence of draws (blue, white, blue), we now consider that as our <em>current</em> model (or information) we know about the process. So if we took another draw, we can consider our current information as the <em>prior</em> knowledge, and combine that with the number of ways we could observe the next blue marble:</p>
<p><em>Original</em></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, ways, <span class="at">posterior_probability =</span> ways <span class="sc">/</span> <span class="fu">sum</span>(ways))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>        p ways posterior_probability
[1,] 0.00    0                  0.00
[2,] 0.25    3                  0.15
[3,] 0.50    8                  0.40
[4,] 0.75    9                  0.45
[5,] 1.00    0                  0.00</code></pre>
</div>
</div>
<p><em>New</em></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># New marble drawn blue</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>X_new <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of trials</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>N_new <span class="ot">&lt;-</span> <span class="fu">length</span>(X_new)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># How many ways could this happen for each p?</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>ways_new <span class="ot">&lt;-</span> (marbles <span class="sc">*</span> p)<span class="sc">^</span>X_new <span class="sc">*</span> (marbles <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>p))<span class="sc">^</span>(N_new<span class="sc">-</span>X_new)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of ways to observe the new sequence, given our prior information</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> ways</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>posterior_ways <span class="ot">&lt;-</span> ways_new <span class="sc">*</span> prior</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, ways_new, prior, posterior_ways, <span class="at">posterior_probability =</span> posterior_ways <span class="sc">/</span> <span class="fu">sum</span>(posterior_ways))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>        p ways_new prior posterior_ways posterior_probability
[1,] 0.00        0     0              0            0.00000000
[2,] 0.25        1     3              3            0.06521739
[3,] 0.50        2     8             16            0.34782609
[4,] 0.75        3     9             27            0.58695652
[5,] 1.00        4     0              0            0.00000000</code></pre>
</div>
</div>
<p>Now this is sort of trivial, because this is the <em>same</em> as if we just thought of counting the full sequence of 4 draws:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Possible values of p</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, .<span class="dv">25</span>, .<span class="dv">5</span>, .<span class="dv">75</span>, <span class="dv">1</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>marbles <span class="ot">&lt;-</span> <span class="fu">length</span>(p) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of samples</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Observed sequence (1 = blue, 0 = white)</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">sum</span>(X)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co"># How many ways could this happen for each p?</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>ways <span class="ot">&lt;-</span> (marbles <span class="sc">*</span> p)<span class="sc">^</span>X <span class="sc">*</span> (marbles <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>p))<span class="sc">^</span>(N<span class="sc">-</span>X)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, ways, <span class="at">posterior_probability =</span> ways <span class="sc">/</span> <span class="fu">sum</span>(ways))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>        p ways posterior_probability
[1,] 0.00    0            0.00000000
[2,] 0.25    3            0.06521739
[3,] 0.50   16            0.34782609
[4,] 0.75   27            0.58695652
[5,] 1.00    0            0.00000000</code></pre>
</div>
</div>
<p>This gets at something that was always murky in Bayesian updating: wouldn’t (or shouldn’t) your <em>priors</em> technically always reflect the most recent information, up to the very second? Meaning that if we set an initial prior, and then collected a single sample, and updated our model, shouldn’t the posterior of that model now be our prior for any subsequent estimate? Well, yes, and it turns out (as we’ve shown about) that these are equivalent ways to think about the mathematical procedure, because you are just enumerating the ways that your sequence of observations could have been observed. So the important piece is just capturing what you know about the parameters at the beginning, and also reflecting any additional information that comes about in the proceeding utilization of information.</p>
<p>I could just wait until <em>all</em> my data is collected over some period of time, combine that with original priors, and get some estimate, or I could sequentially run my estimation procedure each time as a new observation comes in, with everything prior to that being reflected in a prior–it is the same thing. <em>The key is our assumption about how that intermediate information is being generated sequentially–if we learn additional information after say, the 10th sample, that was never known before, we can then incorporate that into our estimation at that point in time</em>.</p>
<blockquote class="blockquote">
<p>“This updating approach amounts to nothing more than asserting that (1) when we have previous information suggesting there are <em>W</em> ways for a conjecture to produce a previous observation <em>D</em> and (2) we acquire new observations _D*_ that the same conjecture can produce in _W*_ ways, then (3) the number of ways the conjecture can account for both <em>D</em> as well as _D*_ is just the produce <em>W</em> X _W*_…Multiplication is just a shortcut to enumerating and counting up all of the paths through the garden that counld produce all the observations.” (25)</p>
</blockquote>
<p>The example he gives to demonstrate the point on “additional information in between draws” is if suddenly you knew something about how the bags of marbles are produced (which is new data in a different form), which implies that there will be no bags containing all white or all blue marbles, three times as many containing only one blue marble and two times as many containing two blue marbles, both vs.&nbsp;one white marble, then we can now updating our <em>current</em> knowledge from the draws we’ve already done with this new information:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># What we know NOW</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> posterior_ways</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Relative counts of the conjectures</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>counts <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># New ways</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>ways_new <span class="ot">&lt;-</span> prior <span class="sc">*</span> counts</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, prior, counts, ways_new, <span class="at">posterior_probability =</span> ways_new <span class="sc">/</span> <span class="fu">sum</span>(ways_new))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>        p prior counts ways_new posterior_probability
[1,] 0.00     0      0        0             0.0000000
[2,] 0.25     3      3        9             0.1323529
[3,] 0.50    16      2       32             0.4705882
[4,] 0.75    27      1       27             0.3970588
[5,] 1.00     0      0        0             0.0000000</code></pre>
</div>
</div>
<p>Notice that <em>if</em> we had known about the bag proportions before we did any draws, that would have been the more intuitive prior distribution to start with, yet we would have reached the <em>same</em> answer. We’re just enumerating possibilities based on the information we receive.</p>
<p>In this vain, he rarely recommends that we would use a “principle of indifference” (i.e., act like we know <em>nothing</em> about the parameters beforehand, and treat them all as equally likely):</p>
<blockquote class="blockquote">
<p>“This book does not use nor endorse”ignorance” priors. As we’ll see in later chapters, the structure of the model and the scientific context always provide information that allows us to do better than ignorance.” (26)</p>
</blockquote>
<p>This is obviously true. There is no circumstance where we should claim we know <em>absolutely nothing</em> about. Even if it is just a little, include it in the model.</p>
</section>
</section>
<section id="building-a-model" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="building-a-model"><span class="header-section-number">2.2</span> Building a model</h2>
<p>He characterizes the model building process into three steps, which supports our previous profundity about Bayesian thinking: switching from thinking about the <em>data</em> to the <em>model</em>, and only use data as a fleeting piece of information to fine tune that model. The three steps are:</p>
<ul>
<li>Data story: Thinking about the <em>data-generating process</em> (no data included)</li>
<li>Update: Use your data to now revise, or as he says, “educate” your model based on evidence</li>
<li>Evaluate: That is your model as of <em>now</em>, but up to this point in time, we may need to change it</li>
</ul>
<blockquote class="blockquote">
<p>“But all data stories are complete, in the sense that they are sufficient for specifying an algorithm for simulating new data.” (28)</p>
</blockquote>
<p>This is profound. Because once we specify the data-generating process, we <em>think</em> we now know (to the best of our knowledge), how an subsequent data would be generated. Thus, we don’t actually need real data to begin evaluating the truth to our model. We can start simulating it and see how it plays out. If stuff starts to look how it does it real life, we may be on the right track, and then could move forward with getting real data to inform our estimates.</p>
<blockquote class="blockquote">
<p>“When you are forced to consider sampling and measurement and make a precise statement of how temperature predicts ran, many stories and resulting models will be consistent with the same vague hypothesis. Resolving that ambiguity often leads to important realizations and model revisions, before any model is fit to data.” (29)</p>
</blockquote>
<p>This is exactly my point I made in <a href="chapter1.html#sec-flaws-in-falsifiability" class="quarto-xref"><span>Section 1.2.1</span></a>. There are infinite ways to procedurally carry out a study answering the same question (i.e., how you define things, how data is collected (exactly), every detailed assumption made along the way, etc.). All of these nuances can have drastic effects on the ultimate conclusions made.</p>
<section id="updatingpriors" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="updatingpriors"><span class="header-section-number">2.2.1</span> Updating priors</h3>
<p>He goes through the concept of what Bayesian updating is to get a feel for it. We can recreate Figure 2.5 (page 30) to better intuit what is happening behind the scenes.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># The observed sample sequence</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>observed_sample <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>) <span class="co"># 1 = water; 0 = land</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="fu">length</span>(observed_sample)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Approximate the set of inifinite p-values by a large set of discrete ones</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>p_continuous <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">01</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the prior probability (uniform over the possibly choices)</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">length</span>(p_continuous), <span class="fu">length</span>(p_continuous))</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the current posterior as the prior (before any data collected)</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>last_posterior <span class="ot">&lt;-</span> prior</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Make result set</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">tibble</span>()</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="co"># For each value in the observed sample </span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) {</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 1. Get the sub-sample</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>  sub_sample <span class="ot">&lt;-</span> observed_sample[<span class="dv">1</span><span class="sc">:</span>i]</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 2. Compute metrics (the number of water samples, and the total number of spins)</span></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>  W_temp <span class="ot">&lt;-</span> <span class="fu">sum</span>(sub_sample)</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>  N_temp <span class="ot">&lt;-</span> <span class="fu">length</span>(sub_sample)</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 3. Compute the likelihood for each p</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>  temp_likelihood <span class="ot">&lt;-</span> p_continuous<span class="sc">^</span>W_temp <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p_continuous)<span class="sc">^</span>(N_temp <span class="sc">-</span> W_temp)</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 4. Posterior</span></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>  temp_posterior <span class="ot">&lt;-</span> temp_likelihood <span class="sc">/</span> <span class="fu">sum</span>(temp_likelihood)</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 5. Add to results</span></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>  results <span class="ot">&lt;-</span></span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>    results <span class="sc">|&gt;</span></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>(</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tibble</span>(</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>        <span class="at">sample =</span> i,</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>        <span class="at">sequence =</span> <span class="fu">paste</span>(sub_sample, <span class="at">collapse =</span> <span class="st">","</span>),</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a>        p_continuous,</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>        <span class="at">likelihood =</span> temp_likelihood,</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a>        <span class="at">current =</span> temp_posterior,</span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a>        <span class="at">last =</span> last_posterior</span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Set the new last posterior</span></span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a>  last_posterior <span class="ot">&lt;-</span> temp_posterior</span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a>results <span class="sc">|&gt;</span></span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Send down the rows</span></span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a>    <span class="at">cols =</span> <span class="fu">c</span>(last, current)</span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb15-62"><a href="#cb15-62" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb15-63"><a href="#cb15-63" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(</span>
<span id="cb15-64"><a href="#cb15-64" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb15-65"><a href="#cb15-65" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> p_continuous,</span>
<span id="cb15-66"><a href="#cb15-66" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> value,</span>
<span id="cb15-67"><a href="#cb15-67" aria-hidden="true" tabindex="-1"></a>      <span class="at">fill =</span> name</span>
<span id="cb15-68"><a href="#cb15-68" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb15-69"><a href="#cb15-69" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb15-70"><a href="#cb15-70" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> .<span class="dv">65</span>,</span>
<span id="cb15-71"><a href="#cb15-71" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="st">"identity"</span></span>
<span id="cb15-72"><a href="#cb15-72" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb15-73"><a href="#cb15-73" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(</span>
<span id="cb15-74"><a href="#cb15-74" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span><span class="fu">paste0</span>(<span class="st">"Spin: "</span>, <span class="fu">factor</span>(sample), <span class="st">" </span><span class="sc">\n</span><span class="st">Sample: "</span>, sequence)</span>
<span id="cb15-75"><a href="#cb15-75" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb15-76"><a href="#cb15-76" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb15-77"><a href="#cb15-77" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">"top"</span>,</span>
<span id="cb15-78"><a href="#cb15-78" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.background =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb15-79"><a href="#cb15-79" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.grid.major.y =</span> <span class="fu">element_line</span>(<span class="at">colour =</span> <span class="st">"gray"</span>),</span>
<span id="cb15-80"><a href="#cb15-80" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb15-81"><a href="#cb15-81" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb15-82"><a href="#cb15-82" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb15-83"><a href="#cb15-83" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"p"</span>) <span class="sc">+</span></span>
<span id="cb15-84"><a href="#cb15-84" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Posterior Probability"</span>) <span class="sc">+</span></span>
<span id="cb15-85"><a href="#cb15-85" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb15-86"><a href="#cb15-86" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"Posterior"</span></span>
<span id="cb15-87"><a href="#cb15-87" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb15-88"><a href="#cb15-88" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(</span>
<span id="cb15-89"><a href="#cb15-89" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"darkgray"</span>)</span>
<span id="cb15-90"><a href="#cb15-90" aria-hidden="true" tabindex="-1"></a>  ) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter2_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><em>Note that this is actually just a discrete approximation of the true continuous, analytical solution, but it covers the idea of what is going on. I previously went in depth on this specific problem from the book <a href="https://www.zajichekstats.com/post/statistical-rethinking-2023-class-notes/#lecture2">here</a> which provides much more detail and code.</em></p>
<blockquote class="blockquote">
<p>“Notice that every updated set of plausibilities becomes the initial plausibilities for the next observation. Every conclusion is the starting point for future inference.” (31)</p>
</blockquote>
<p>This supports the idea that our <em>model</em> is the living, breathing thing, and that we should use everything we know up to <em>now</em> to inform it. Then use new information to subsequently update it as time goes on. <em>Our model is never complete</em>.</p>
<p>Another crucial point about considering sequential updates versus using your entire data set in a single updating step:</p>
<blockquote class="blockquote">
<p>“So the data could be presented to your model in any order, or all at once even. In most cases, you will present the data all at once, for the sake of convenience. But it’s important to realize that this merely represents abbreviation of an iterated learning process.” (31)</p>
</blockquote>
<p>There is a catch though, as reflected later:</p>
<blockquote class="blockquote">
<p>“That is only true, however, because the model assumes that order is irrelevant to inference. When something is irrelevant to the machine, it won’t affect the inference directly. But it may affect it indirectly, because the data will depend upon order.” (31)</p>
</blockquote>
<p>Hence the importance of <em>understanding</em> the data-generating process.</p>
</section>
<section id="bayesian-models-need-no-data" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="bayesian-models-need-no-data"><span class="header-section-number">2.2.2</span> Bayesian models need no data</h3>
<p>In the <em>Rethinking</em> box on page 31, he discusses a crucial point related to what we’ve talked about: that there is no sample size requirement for Bayesian inference. This again is a <em>key</em> reason why this paradigm is superior. We aren’t stuck in asymptotics and arbitrary sample size cutoffs (e.g., N=30). We can specify our model, with prior information, using the best available knowledge we have up to this point in time, and actually get reliable estimates. Then as we collect a single observation, our new (posterior) estimates will nicely update to reflect the (likely little) amount of information contained in it, instead of needing to gather a bunch of data in order to get even get something interpretable. I previously discussed this in depth with an example here:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/bUerkVsCwtA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="tie-inferences-back-to-what-matters" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="tie-inferences-back-to-what-matters"><span class="header-section-number">2.2.3</span> Tie inferences back to what matters</h3>
<p>It’s not enough to just provide an estimate and say “it matters” or not, like we arbitrarily do with frequentist p-values and 5% thresholds. These are empty statements. And again, for a result to be meaningful, we need to <em>feel it in our bones</em>. If all results were presented with such relevance, there wouldn’t be so much controversy about the value of “science”. This problem in large part in our society is due to the lacksidasical approach to assigning meaning to estimates, declaring scientific certainty, and not actually doing to the due diligence of acknowledging nuances to why some things matter to some people and some don’t.</p>
<p>This point is hit on in the <em>Evaluate</em> section (2.2.3) of the book:</p>
<blockquote class="blockquote">
<p>“Instead, the objective is to check the model’s adequacy for some purpose. This usually means asking and answering additional questions, beyond those that originally constructed the model. Both the questions and answers will depend upon the scientific context.” (32)</p>
</blockquote>
<p>When we just blindly run statistical tests, get a p-value less than 5%, and then declare that “science shows this thing, and anyone who disregards it is anti-science”, we’ve entered into something that is more religious, not scientific. Because we haven’t actually convinced the person that these results matter. It is our job to frame scientific questions, their scope, and the subsequent results/interpretation closer something tangible that makes people <em>feel</em> the results.</p>
<p>As the great book <a href="https://press.umich.edu/Books/T/The-Cult-of-Statistical-Significance2">The Cult of Statistical Significance: How the Standard Error Costs Us Jobs, Justice, and Lives</a> says:</p>
<blockquote class="blockquote">
<p>“Real science changes one’s mind. That’s one way to see that the proliferation of unpersuasive significance tests is not real science.” (page 112)</p>
</blockquote>
<p>and</p>
<blockquote class="blockquote">
<p>“She can test her belief in the price effect by looking at the magnitudes, using, for example, the highly advanced technique common in data-heavy articles in physics journals: ‘interocular trauma’. That is, she can look and see if the result hits her between the eyes.” (page 72)</p>
</blockquote>
<p>See a much more extensive discussion of this book, and a large list of quotes from that book that I love, <a href="https://www.zajichekstats.com/post/statistical-significance-is-insignificant/">here</a>.</p>
</section>
<section id="is-bayesian-modeling-subjective" class="level3" data-number="2.2.4">
<h3 data-number="2.2.4" class="anchored" data-anchor-id="is-bayesian-modeling-subjective"><span class="header-section-number">2.2.4</span> Is Bayesian modeling subjective?</h3>
<p>A common critique of Bayesian modeling is that it is inherently subjective, because people choose their priors. I once thought of it that way as well, until I listed to <a href="https://learnbayesstats.com/episode/45-biostats-clinical-trial-design-frank-harrell">this episode</a> of <em>Learning Bayesian Statistics</em>. Frank Harrell argues, and I now agree, that it is even less subjective because we are actually accounting for what we know, not just being forced into blind assumptions that occur in the frequentist paradigm. This is emphasized on page 35:</p>
<blockquote class="blockquote">
<p>“None of this should be understood to mean that any statistical analysis is not inherently subjective, because of course it is–lots of little subjective decisions are involved in all parts of science. It’s just that priors and Bayesian data analysis are no more inherently subjective than are likelihoods and the repeat sampling assumptions required for significance testing…No one is required to swear an oath to the assumptions of a model, and no set of assumptions deserves our obedience.” (35)</p>
</blockquote>
</section>
</section>
<section id="making-your-model-work" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="making-your-model-work"><span class="header-section-number">2.3</span> Making Your Model Work</h2>
<blockquote class="blockquote">
<p>“However, knowing the mathematical rule is often of little help, because many of the interesting models in contemporary science cannot be conditioned formally, no matter your skill in mathematics. And while some broadly useful models like linear regression can be conditioned formally, this is only possible if you constrain your choice of prior to special forms that are easy to do mathematics with. We’d like to avoid forced modeling choices ot this kind, instead favoring conditioning engines that can accomodate whichever prior is most useful for inference” (39)</p>
</blockquote>
<p>One challenge in Bayesian analysis, and having the theoretical flexibility for specifying priors (and models in general) that best represent what you know, is that it doesn’t always work out “nicely” mathematically. Most common statistical methods are used because the math works out, so we can have software that fits things according to that assumed structure. Similarly, in the Bayesian framework, for certain models, there are “nice” choices you can make for prior that make the posterior work out analytically (closed form solutions), which makes it easier to deal.</p>
<p>But we don’t necessarily want to restrict ourselves to choosing model structures and assumptions for the sake of mathematical convenience. We want to specify our models to reflect what we actually believe to be true. That means we may have very messy functions pulled out of our brain (e.g., step functions, weird shapes, etc.). But if that’s what makes most sense scientifically, we want to have flexible estimating engines to allow us to do this and implement it. That’s what motivates the need for things he talks about next, like <em>markov chain monte carlo (MCMC)</em> simulation or quadratic approximation. These things let us focus on specifying models that we think make sense, regardless how the math plays out downstream. He calls these <em>conditioning engines</em>.</p>
<section id="grid-approximation" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="grid-approximation"><span class="header-section-number">2.3.1</span> Grid approximation</h3>
<p>This is what we did <a href="#updatingpriors">above</a>. We know that the true parameter value (<span class="math inline">\(p\)</span>) could be anything (as it is continuous), but we approximated what the posterior would look like by chopping up its domain into small intervals and computing pseudo-discrete posteriors based on that. The yielding plots reflect <em>approximately</em> what the actual posterior would look like if we derived the full analytical solution. I think this is a great way to do it, at least to start, because you can get into the “ballpark” of your posterior, and if for some reason that ends up not being specific enough to satisfy your inquiry, you can look to more complex methods to refine your estimates in a more complete way.</p>
</section>
<section id="quadratic-approximation" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="quadratic-approximation"><span class="header-section-number">2.3.2</span> Quadratic approximation</h3>
<blockquote class="blockquote">
<p>“Under quite general conditions, the region near the peak of the posterior distribution will be nearly Gaussian. This means the posterior distribution can be usefully approximated by a Gaussian distribution.” (42)</p>
</blockquote>
<p>When we get more parameters in the model, we can’t be specifying large grids of parameters to approximate, so we need something else. The quadratic approximation takes advantage of properties of posteriors (that, locally, they tend to be Gaussian), and that Gaussian distributions can be described by only the <em>mean</em> and <em>variance</em>.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rethinking)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: cmdstanr</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'cmdstanr' was built under R version 4.4.2</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>This is cmdstanr version 0.8.1</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>- Use set_cmdstan_path() to set the path to CmdStan</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>- Use install_cmdstan() to install CmdStan</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: posterior</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>This is posterior version 1.6.0</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'posterior'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:stats':

    mad, sd, var</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:base':

    %in%, match</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: parallel</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>rethinking (Version 2.42)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'rethinking'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:purrr':

    map</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:stats':

    rstudent</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>globe.pa <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    W <span class="sc">~</span> <span class="fu">dbinom</span>(W<span class="sc">+</span>L, p),</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    p <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> <span class="fu">list</span>(<span class="at">W =</span> <span class="dv">6</span>, <span class="at">L =</span> <span class="dv">3</span>)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(globe.pa)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>      mean        sd     5.5%    94.5%
p 0.666667 0.1571337 0.415537 0.917797</code></pre>
</div>
</div>
</section>
<section id="markov-chain-monte-carlo-mcmc" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="markov-chain-monte-carlo-mcmc"><span class="header-section-number">2.3.3</span> Markov chain Monte Carlo (MCMC)</h3>
<blockquote class="blockquote">
<p>“The conceptual challenge of MCMC lies in its highly non-obvious strategy. Instead of attempting to compute or approximate the posterior distribution directly, MCMC techniques merely draw samples from the posterior. You end up with a collection of parameter values, and the frequencies of these values correspond to the posterior plauibilities.” (45)</p>
</blockquote>
<p><br></p>
<p><em>Video Lecture From the Author</em></p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/R1vcdhPBlXA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter1.html" class="pagination-link" aria-label="The Golem of Prague">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Golem of Prague</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter3.html" class="pagination-link" aria-label="Sampling the Imaginary">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Sampling the Imaginary</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb35" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Small Worlds and Large Worlds</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Colombo </span><span class="co">[</span><span class="ot">Christopher Columbus</span><span class="co">]</span><span class="at"> made a prediction based upon his view that the world was small. But since he lived in a large world, aspects of the prediction were wrong. In his case, the error was lucky." (19)</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>All models are and will always be wrong, that's why they are called models. The "small world" represented by the model can only hope to be reflective of "large world", the actual environment in which the model, insights, and inference that come out of it are used (i.e., where the rubber meets the road).</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="fu">## Unraveling the counting process</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>The "garden of forking paths" idea is about stretching out the process for counting things. Often in statistics, we just use formulas, or integrals, or whatever other notation to think through logic in our heads. This fundamental, systematic approach to counting lets us see what's really going on behind the scenes. Ultimately, this leads to a more intuitive understanding of what Bayesian modeling is (in McElreath's words): _"really just counting and comparing of possibilities"_ (20).</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="fu">### First, the likelihood</span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>In the marble example, he starts by counting the number of ways a particular observed sequence of marble draws could have occurred _given_ an assumed true state of the bag (i.e., a hypothesis, which he calls _conjecture_). Then proceeds to manually count (and draw) the possibilities--nothing fancy about it, just brute force. Once this count is obtained, the question becomes: _what is this collection of counts for all other possible states of the bag?_. This is getting at what Bayesian analysis fundamentally is: determining which state of the world is most likely given the evidence.</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "By comparing these counts, we have part of a solution for a way to rate the relative plausibility of each conjectured bag composition." (23)</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>The word _relative_ foreshadows many implications in Bayesian analysis, such as the focus on priors and likelihoods (not the normalizing constant), the different approaches to getting at the same answer (counts, rates, etc.), and the focus of comparing possible hypotheses relative to one another (and the whole slate of possibilities).</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Translating to familar notation</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>Since I come at this from the "traditional" statistical point of view, it's helpful to reconcile the approach here with the way I would typically think about it. Namely, we have a bag with four (4) marbles in it, each one being white or blue. Based on a sample from the bag, we want to infer what make up of all marbles is. Thus, the unknown parameter can be thought of as $p$, the proportion of marbles that are blue (or white if we wanted). So, $p$ can be one of five choices: $p \in (0, .25, .5, .75, 1)$. On page 21 it was stated that _"a sequence of three marbles is pulled from the bag, one at a time, replacing the marble each time and shaking the bag before drawing another marble"_--so we are _assuming_ that we are selecting randomly with replacement (as a side note, a key point is our assumption: *we are using our judgement that the sampling method (shaking randomly) is sufficient to assume random, independent draws, but this paradigm leaves the possibility to account for modeling steps where this assumption may not be valid).*</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>If we take $N=3$ draws and $X=2$ is the number that were blue, then we can think of:</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>$X \sim Binomial(N=3, p)$</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>And we get the following counts of possible ways to observe this sequence for each value of $p$.</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Possible values of p</span></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, .<span class="dv">25</span>, .<span class="dv">5</span>, .<span class="dv">75</span>, <span class="dv">1</span>)</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>marbles <span class="ot">&lt;-</span> <span class="fu">length</span>(p) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of samples</span></span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Observed sequence (1 = blue, 0 = white)</span></span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">sum</span>(X)</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a><span class="co"># How many ways could this happen for each p?</span></span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a>ways <span class="ot">&lt;-</span> (marbles <span class="sc">*</span> p)<span class="sc">^</span>X <span class="sc">*</span> (marbles <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>p))<span class="sc">^</span>(N<span class="sc">-</span>X)</span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, ways, <span class="at">posterior_probability =</span> ways <span class="sc">/</span> <span class="fu">sum</span>(ways))</span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a>This matches what is in the book on page 23. Why? Well because there is a finite number of marbles, and we are re-scaling to be in absolute terms relative to that, instead of being in rate terms. The point is that we can think of the counting process in absolute magnitude (counts), relative (probabilities), or even likelihoods (basically, non-normalized probabilities). They will all produce the _same_ posterior probability suggesting that the bag most likely has 3 blue marbles, because our calculation is _relative_ to span of possible hypotheses (conjectures). </span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a>Here we use the full <span class="co">[</span><span class="ot">binomial</span><span class="co">](https://en.wikipedia.org/wiki/Binomial_distribution)</span> distribution for our calculations:</span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute traditional binomial probabilities</span></span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a>binom_probs <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="at">x =</span> X, <span class="at">size =</span> N, <span class="at">prob =</span> p)</span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, binom_probs, <span class="at">posterior_probability =</span> binom_probs <span class="sc">/</span> <span class="fu">sum</span>(binom_probs))</span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a>Now we could even do it without it being normalized (i.e., we don't care if it adds to 1):</span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-66"><a href="#cb35-66" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb35-67"><a href="#cb35-67" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute unnormalized probabilities</span></span>
<span id="cb35-68"><a href="#cb35-68" aria-hidden="true" tabindex="-1"></a>unnorm_probs <span class="ot">&lt;-</span> p<span class="sc">^</span>X <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">^</span>(N<span class="sc">-</span>X)</span>
<span id="cb35-69"><a href="#cb35-69" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, unnorm_probs, <span class="at">posterior_probability =</span> unnorm_probs <span class="sc">/</span> <span class="fu">sum</span>(unnorm_probs))</span>
<span id="cb35-70"><a href="#cb35-70" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-71"><a href="#cb35-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-72"><a href="#cb35-72" aria-hidden="true" tabindex="-1"></a>They all lead to same _relative_ posterior probability (3 blue marbles).</span>
<span id="cb35-73"><a href="#cb35-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-74"><a href="#cb35-74" aria-hidden="true" tabindex="-1"></a>One key caveat here that comes next: these results assume that each value of $p$ is equally likely. But as he points out:</span>
<span id="cb35-75"><a href="#cb35-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-76"><a href="#cb35-76" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "We may have additional information about the relative plausibility of each conjecture. This information could arise from knowledge of how the contens of the bag were generated." (25)</span></span>
<span id="cb35-77"><a href="#cb35-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-78"><a href="#cb35-78" aria-hidden="true" tabindex="-1"></a>This gets at the idea of a _prior_ distribution. We may know something about how the bag was arranged, such that we have an inkling that a particular value of $p$ is more likely to be true than the rest. In that case, what we have done above doesn't work.</span>
<span id="cb35-79"><a href="#cb35-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-80"><a href="#cb35-80" aria-hidden="true" tabindex="-1"></a><span class="fu">### Incorporating prior knowledge</span></span>
<span id="cb35-81"><a href="#cb35-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-82"><a href="#cb35-82" aria-hidden="true" tabindex="-1"></a>Since we've just established the number of ways to observe the original sequence of draws (blue, white, blue), we now consider that as our _current_ model (or information) we know about the process. So if we took another draw, we can consider our current information as the _prior_ knowledge, and combine that with the number of ways we could observe the next blue marble:</span>
<span id="cb35-83"><a href="#cb35-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-84"><a href="#cb35-84" aria-hidden="true" tabindex="-1"></a>_Original_</span>
<span id="cb35-87"><a href="#cb35-87" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb35-88"><a href="#cb35-88" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, ways, <span class="at">posterior_probability =</span> ways <span class="sc">/</span> <span class="fu">sum</span>(ways))</span>
<span id="cb35-89"><a href="#cb35-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-90"><a href="#cb35-90" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-91"><a href="#cb35-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-92"><a href="#cb35-92" aria-hidden="true" tabindex="-1"></a>_New_</span>
<span id="cb35-95"><a href="#cb35-95" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb35-96"><a href="#cb35-96" aria-hidden="true" tabindex="-1"></a><span class="co"># New marble drawn blue</span></span>
<span id="cb35-97"><a href="#cb35-97" aria-hidden="true" tabindex="-1"></a>X_new <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb35-98"><a href="#cb35-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-99"><a href="#cb35-99" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of trials</span></span>
<span id="cb35-100"><a href="#cb35-100" aria-hidden="true" tabindex="-1"></a>N_new <span class="ot">&lt;-</span> <span class="fu">length</span>(X_new)</span>
<span id="cb35-101"><a href="#cb35-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-102"><a href="#cb35-102" aria-hidden="true" tabindex="-1"></a><span class="co"># How many ways could this happen for each p?</span></span>
<span id="cb35-103"><a href="#cb35-103" aria-hidden="true" tabindex="-1"></a>ways_new <span class="ot">&lt;-</span> (marbles <span class="sc">*</span> p)<span class="sc">^</span>X_new <span class="sc">*</span> (marbles <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>p))<span class="sc">^</span>(N_new<span class="sc">-</span>X_new)</span>
<span id="cb35-104"><a href="#cb35-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-105"><a href="#cb35-105" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of ways to observe the new sequence, given our prior information</span></span>
<span id="cb35-106"><a href="#cb35-106" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> ways</span>
<span id="cb35-107"><a href="#cb35-107" aria-hidden="true" tabindex="-1"></a>posterior_ways <span class="ot">&lt;-</span> ways_new <span class="sc">*</span> prior</span>
<span id="cb35-108"><a href="#cb35-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-109"><a href="#cb35-109" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, ways_new, prior, posterior_ways, <span class="at">posterior_probability =</span> posterior_ways <span class="sc">/</span> <span class="fu">sum</span>(posterior_ways))</span>
<span id="cb35-110"><a href="#cb35-110" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-111"><a href="#cb35-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-112"><a href="#cb35-112" aria-hidden="true" tabindex="-1"></a>Now this is sort of trivial, because this is the _same_ as if we just thought of counting the full sequence of 4 draws:</span>
<span id="cb35-113"><a href="#cb35-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-116"><a href="#cb35-116" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb35-117"><a href="#cb35-117" aria-hidden="true" tabindex="-1"></a><span class="co"># Possible values of p</span></span>
<span id="cb35-118"><a href="#cb35-118" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, .<span class="dv">25</span>, .<span class="dv">5</span>, .<span class="dv">75</span>, <span class="dv">1</span>)</span>
<span id="cb35-119"><a href="#cb35-119" aria-hidden="true" tabindex="-1"></a>marbles <span class="ot">&lt;-</span> <span class="fu">length</span>(p) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb35-120"><a href="#cb35-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-121"><a href="#cb35-121" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of samples</span></span>
<span id="cb35-122"><a href="#cb35-122" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb35-123"><a href="#cb35-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-124"><a href="#cb35-124" aria-hidden="true" tabindex="-1"></a><span class="co"># Observed sequence (1 = blue, 0 = white)</span></span>
<span id="cb35-125"><a href="#cb35-125" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb35-126"><a href="#cb35-126" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">sum</span>(X)</span>
<span id="cb35-127"><a href="#cb35-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-128"><a href="#cb35-128" aria-hidden="true" tabindex="-1"></a><span class="co"># How many ways could this happen for each p?</span></span>
<span id="cb35-129"><a href="#cb35-129" aria-hidden="true" tabindex="-1"></a>ways <span class="ot">&lt;-</span> (marbles <span class="sc">*</span> p)<span class="sc">^</span>X <span class="sc">*</span> (marbles <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>p))<span class="sc">^</span>(N<span class="sc">-</span>X)</span>
<span id="cb35-130"><a href="#cb35-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-131"><a href="#cb35-131" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, ways, <span class="at">posterior_probability =</span> ways <span class="sc">/</span> <span class="fu">sum</span>(ways))</span>
<span id="cb35-132"><a href="#cb35-132" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-133"><a href="#cb35-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-134"><a href="#cb35-134" aria-hidden="true" tabindex="-1"></a>This gets at something that was always murky in Bayesian updating: wouldn't (or shouldn't) your _priors_ technically always reflect the most recent information, up to the very second? Meaning that if we set an initial prior, and then collected a single sample, and updated our model, shouldn't the posterior of that model now be our prior for any subsequent estimate? Well, yes, and it turns out (as we've shown about) that these are equivalent ways to think about the mathematical procedure, because you are just enumerating the ways that your sequence of observations could have been observed. So the important piece is just capturing what you know about the parameters at the beginning, and also reflecting any additional information that comes about in the proceeding utilization of information.</span>
<span id="cb35-135"><a href="#cb35-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-136"><a href="#cb35-136" aria-hidden="true" tabindex="-1"></a>I could just wait until _all_ my data is collected over some period of time, combine that with original priors, and get some estimate, or I could sequentially run my estimation procedure each time as a new observation comes in, with everything prior to that being reflected in a prior--it is the same thing. *The key is our assumption about how that intermediate information is being generated sequentially--if we learn additional information after say, the 10th sample, that was never known before, we can then incorporate that into our estimation at that point in time*.</span>
<span id="cb35-137"><a href="#cb35-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-138"><a href="#cb35-138" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "This updating approach amounts to nothing more than asserting that (1) when we have previous information suggesting there are _W_ ways for a conjecture to produce a previous observation _D_ and (2) we acquire new observations _D*_ that the same conjecture can produce in _W*_ ways, then (3) the number of ways the conjecture can account for both _D_ as well as _D*_ is just the produce _W_ X _W*_...Multiplication is just a shortcut to enumerating and counting up all of the paths through the garden that counld produce all the observations." (25)</span></span>
<span id="cb35-139"><a href="#cb35-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-140"><a href="#cb35-140" aria-hidden="true" tabindex="-1"></a>The example he gives to demonstrate the point on "additional information in between draws" is if suddenly you knew something about how the bags of marbles are produced (which is new data in a different form), which implies that there will be no bags containing all white or all blue marbles, three times as many containing only one blue marble and two times as many containing two blue marbles, both vs. one white marble, then we can now updating our _current_ knowledge from the draws we've already done with this new information:</span>
<span id="cb35-141"><a href="#cb35-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-144"><a href="#cb35-144" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb35-145"><a href="#cb35-145" aria-hidden="true" tabindex="-1"></a><span class="co"># What we know NOW</span></span>
<span id="cb35-146"><a href="#cb35-146" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> posterior_ways</span>
<span id="cb35-147"><a href="#cb35-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-148"><a href="#cb35-148" aria-hidden="true" tabindex="-1"></a><span class="co"># Relative counts of the conjectures</span></span>
<span id="cb35-149"><a href="#cb35-149" aria-hidden="true" tabindex="-1"></a>counts <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb35-150"><a href="#cb35-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-151"><a href="#cb35-151" aria-hidden="true" tabindex="-1"></a><span class="co"># New ways</span></span>
<span id="cb35-152"><a href="#cb35-152" aria-hidden="true" tabindex="-1"></a>ways_new <span class="ot">&lt;-</span> prior <span class="sc">*</span> counts</span>
<span id="cb35-153"><a href="#cb35-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-154"><a href="#cb35-154" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, prior, counts, ways_new, <span class="at">posterior_probability =</span> ways_new <span class="sc">/</span> <span class="fu">sum</span>(ways_new))</span>
<span id="cb35-155"><a href="#cb35-155" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-156"><a href="#cb35-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-157"><a href="#cb35-157" aria-hidden="true" tabindex="-1"></a>Notice that _if_ we had known about the bag proportions before we did any draws, that would have been the more intuitive prior distribution to start with, yet we would have reached the _same_ answer. We're just enumerating possibilities based on the information we receive.</span>
<span id="cb35-158"><a href="#cb35-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-159"><a href="#cb35-159" aria-hidden="true" tabindex="-1"></a>In this vain, he rarely recommends that we would use a "principle of indifference" (i.e., act like we know _nothing_ about the parameters beforehand, and treat them all as equally likely):</span>
<span id="cb35-160"><a href="#cb35-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-161"><a href="#cb35-161" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "This book does not use nor endorse "ignorance" priors. As we'll see in later chapters, the structure of the model and the scientific context always provide information that allows us to do better than ignorance." (26)</span></span>
<span id="cb35-162"><a href="#cb35-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-163"><a href="#cb35-163" aria-hidden="true" tabindex="-1"></a>This is obviously true. There is no circumstance where we should claim we know _absolutely nothing_ about. Even if it is just a little, include it in the model.</span>
<span id="cb35-164"><a href="#cb35-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-165"><a href="#cb35-165" aria-hidden="true" tabindex="-1"></a><span class="fu">## Building a model</span></span>
<span id="cb35-166"><a href="#cb35-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-167"><a href="#cb35-167" aria-hidden="true" tabindex="-1"></a>He characterizes the model building process into three steps, which supports our previous profundity about Bayesian thinking: switching from thinking about the _data_ to the _model_, and only use data as a fleeting piece of information to fine tune that model. The three steps are:</span>
<span id="cb35-168"><a href="#cb35-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-169"><a href="#cb35-169" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Data story: Thinking about the _data-generating process_ (no data included)</span>
<span id="cb35-170"><a href="#cb35-170" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Update: Use your data to now revise, or as he says, "educate" your model based on evidence</span>
<span id="cb35-171"><a href="#cb35-171" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Evaluate: That is your model as of _now_, but up to this point in time, we may need to change it</span>
<span id="cb35-172"><a href="#cb35-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-173"><a href="#cb35-173" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "But all data stories are complete, in the sense that they are sufficient for specifying an algorithm for simulating new data." (28)</span></span>
<span id="cb35-174"><a href="#cb35-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-175"><a href="#cb35-175" aria-hidden="true" tabindex="-1"></a>This is profound. Because once we specify the data-generating process, we _think_ we now know (to the best of our knowledge), how an subsequent data would be generated. Thus, we don't actually need real data to begin evaluating the truth to our model. We can start simulating it and see how it plays out. If stuff starts to look how it does it real life, we may be on the right track, and then could move forward with getting real data to inform our estimates.</span>
<span id="cb35-176"><a href="#cb35-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-177"><a href="#cb35-177" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "When you are forced to consider sampling and measurement and make a precise statement of how temperature predicts ran, many stories and resulting models will be consistent with the same vague hypothesis. Resolving that ambiguity often leads to important realizations and model revisions, before any model is fit to data." (29)</span></span>
<span id="cb35-178"><a href="#cb35-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-179"><a href="#cb35-179" aria-hidden="true" tabindex="-1"></a>This is exactly my point I made in @sec-flaws-in-falsifiability. There are infinite ways to procedurally carry out a study answering the same question (i.e., how you define things, how data is collected (exactly), every detailed assumption made along the way, etc.). All of these nuances can have drastic effects on the ultimate conclusions made.</span>
<span id="cb35-180"><a href="#cb35-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-181"><a href="#cb35-181" aria-hidden="true" tabindex="-1"></a><span class="fu">### Updating priors {#updatingpriors}</span></span>
<span id="cb35-182"><a href="#cb35-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-183"><a href="#cb35-183" aria-hidden="true" tabindex="-1"></a>He goes through the concept of what Bayesian updating is to get a feel for it. We can recreate Figure 2.5 (page 30) to better intuit what is happening behind the scenes.</span>
<span id="cb35-184"><a href="#cb35-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-185"><a href="#cb35-185" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE}</span></span>
<span id="cb35-186"><a href="#cb35-186" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb35-187"><a href="#cb35-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-188"><a href="#cb35-188" aria-hidden="true" tabindex="-1"></a><span class="co"># The observed sample sequence</span></span>
<span id="cb35-189"><a href="#cb35-189" aria-hidden="true" tabindex="-1"></a>observed_sample <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>) <span class="co"># 1 = water; 0 = land</span></span>
<span id="cb35-190"><a href="#cb35-190" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="fu">length</span>(observed_sample)</span>
<span id="cb35-191"><a href="#cb35-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-192"><a href="#cb35-192" aria-hidden="true" tabindex="-1"></a><span class="co"># Approximate the set of inifinite p-values by a large set of discrete ones</span></span>
<span id="cb35-193"><a href="#cb35-193" aria-hidden="true" tabindex="-1"></a>p_continuous <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">01</span>)</span>
<span id="cb35-194"><a href="#cb35-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-195"><a href="#cb35-195" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the prior probability (uniform over the possibly choices)</span></span>
<span id="cb35-196"><a href="#cb35-196" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">length</span>(p_continuous), <span class="fu">length</span>(p_continuous))</span>
<span id="cb35-197"><a href="#cb35-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-198"><a href="#cb35-198" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the current posterior as the prior (before any data collected)</span></span>
<span id="cb35-199"><a href="#cb35-199" aria-hidden="true" tabindex="-1"></a>last_posterior <span class="ot">&lt;-</span> prior</span>
<span id="cb35-200"><a href="#cb35-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-201"><a href="#cb35-201" aria-hidden="true" tabindex="-1"></a><span class="co"># Make result set</span></span>
<span id="cb35-202"><a href="#cb35-202" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">tibble</span>()</span>
<span id="cb35-203"><a href="#cb35-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-204"><a href="#cb35-204" aria-hidden="true" tabindex="-1"></a><span class="co"># For each value in the observed sample </span></span>
<span id="cb35-205"><a href="#cb35-205" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) {</span>
<span id="cb35-206"><a href="#cb35-206" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-207"><a href="#cb35-207" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 1. Get the sub-sample</span></span>
<span id="cb35-208"><a href="#cb35-208" aria-hidden="true" tabindex="-1"></a>  sub_sample <span class="ot">&lt;-</span> observed_sample[<span class="dv">1</span><span class="sc">:</span>i]</span>
<span id="cb35-209"><a href="#cb35-209" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-210"><a href="#cb35-210" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 2. Compute metrics (the number of water samples, and the total number of spins)</span></span>
<span id="cb35-211"><a href="#cb35-211" aria-hidden="true" tabindex="-1"></a>  W_temp <span class="ot">&lt;-</span> <span class="fu">sum</span>(sub_sample)</span>
<span id="cb35-212"><a href="#cb35-212" aria-hidden="true" tabindex="-1"></a>  N_temp <span class="ot">&lt;-</span> <span class="fu">length</span>(sub_sample)</span>
<span id="cb35-213"><a href="#cb35-213" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-214"><a href="#cb35-214" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 3. Compute the likelihood for each p</span></span>
<span id="cb35-215"><a href="#cb35-215" aria-hidden="true" tabindex="-1"></a>  temp_likelihood <span class="ot">&lt;-</span> p_continuous<span class="sc">^</span>W_temp <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p_continuous)<span class="sc">^</span>(N_temp <span class="sc">-</span> W_temp)</span>
<span id="cb35-216"><a href="#cb35-216" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-217"><a href="#cb35-217" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 4. Posterior</span></span>
<span id="cb35-218"><a href="#cb35-218" aria-hidden="true" tabindex="-1"></a>  temp_posterior <span class="ot">&lt;-</span> temp_likelihood <span class="sc">/</span> <span class="fu">sum</span>(temp_likelihood)</span>
<span id="cb35-219"><a href="#cb35-219" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-220"><a href="#cb35-220" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 5. Add to results</span></span>
<span id="cb35-221"><a href="#cb35-221" aria-hidden="true" tabindex="-1"></a>  results <span class="ot">&lt;-</span></span>
<span id="cb35-222"><a href="#cb35-222" aria-hidden="true" tabindex="-1"></a>    results <span class="sc">|&gt;</span></span>
<span id="cb35-223"><a href="#cb35-223" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>(</span>
<span id="cb35-224"><a href="#cb35-224" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tibble</span>(</span>
<span id="cb35-225"><a href="#cb35-225" aria-hidden="true" tabindex="-1"></a>        <span class="at">sample =</span> i,</span>
<span id="cb35-226"><a href="#cb35-226" aria-hidden="true" tabindex="-1"></a>        <span class="at">sequence =</span> <span class="fu">paste</span>(sub_sample, <span class="at">collapse =</span> <span class="st">","</span>),</span>
<span id="cb35-227"><a href="#cb35-227" aria-hidden="true" tabindex="-1"></a>        p_continuous,</span>
<span id="cb35-228"><a href="#cb35-228" aria-hidden="true" tabindex="-1"></a>        <span class="at">likelihood =</span> temp_likelihood,</span>
<span id="cb35-229"><a href="#cb35-229" aria-hidden="true" tabindex="-1"></a>        <span class="at">current =</span> temp_posterior,</span>
<span id="cb35-230"><a href="#cb35-230" aria-hidden="true" tabindex="-1"></a>        <span class="at">last =</span> last_posterior</span>
<span id="cb35-231"><a href="#cb35-231" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb35-232"><a href="#cb35-232" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb35-233"><a href="#cb35-233" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-234"><a href="#cb35-234" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Set the new last posterior</span></span>
<span id="cb35-235"><a href="#cb35-235" aria-hidden="true" tabindex="-1"></a>  last_posterior <span class="ot">&lt;-</span> temp_posterior</span>
<span id="cb35-236"><a href="#cb35-236" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-237"><a href="#cb35-237" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb35-238"><a href="#cb35-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-239"><a href="#cb35-239" aria-hidden="true" tabindex="-1"></a>results <span class="sc">|&gt;</span></span>
<span id="cb35-240"><a href="#cb35-240" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-241"><a href="#cb35-241" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Send down the rows</span></span>
<span id="cb35-242"><a href="#cb35-242" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb35-243"><a href="#cb35-243" aria-hidden="true" tabindex="-1"></a>    <span class="at">cols =</span> <span class="fu">c</span>(last, current)</span>
<span id="cb35-244"><a href="#cb35-244" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb35-245"><a href="#cb35-245" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-246"><a href="#cb35-246" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb35-247"><a href="#cb35-247" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb35-248"><a href="#cb35-248" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(</span>
<span id="cb35-249"><a href="#cb35-249" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb35-250"><a href="#cb35-250" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> p_continuous,</span>
<span id="cb35-251"><a href="#cb35-251" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> value,</span>
<span id="cb35-252"><a href="#cb35-252" aria-hidden="true" tabindex="-1"></a>      <span class="at">fill =</span> name</span>
<span id="cb35-253"><a href="#cb35-253" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb35-254"><a href="#cb35-254" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb35-255"><a href="#cb35-255" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> .<span class="dv">65</span>,</span>
<span id="cb35-256"><a href="#cb35-256" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="st">"identity"</span></span>
<span id="cb35-257"><a href="#cb35-257" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb35-258"><a href="#cb35-258" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(</span>
<span id="cb35-259"><a href="#cb35-259" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span><span class="fu">paste0</span>(<span class="st">"Spin: "</span>, <span class="fu">factor</span>(sample), <span class="st">" </span><span class="sc">\n</span><span class="st">Sample: "</span>, sequence)</span>
<span id="cb35-260"><a href="#cb35-260" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb35-261"><a href="#cb35-261" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb35-262"><a href="#cb35-262" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">"top"</span>,</span>
<span id="cb35-263"><a href="#cb35-263" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.background =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb35-264"><a href="#cb35-264" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.grid.major.y =</span> <span class="fu">element_line</span>(<span class="at">colour =</span> <span class="st">"gray"</span>),</span>
<span id="cb35-265"><a href="#cb35-265" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb35-266"><a href="#cb35-266" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb35-267"><a href="#cb35-267" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb35-268"><a href="#cb35-268" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"p"</span>) <span class="sc">+</span></span>
<span id="cb35-269"><a href="#cb35-269" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Posterior Probability"</span>) <span class="sc">+</span></span>
<span id="cb35-270"><a href="#cb35-270" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb35-271"><a href="#cb35-271" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"Posterior"</span></span>
<span id="cb35-272"><a href="#cb35-272" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb35-273"><a href="#cb35-273" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(</span>
<span id="cb35-274"><a href="#cb35-274" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"darkgray"</span>)</span>
<span id="cb35-275"><a href="#cb35-275" aria-hidden="true" tabindex="-1"></a>  ) </span>
<span id="cb35-276"><a href="#cb35-276" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-277"><a href="#cb35-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-278"><a href="#cb35-278" aria-hidden="true" tabindex="-1"></a>_Note that this is actually just a discrete approximation of the true continuous, analytical solution, but it covers the idea of what is going on. I previously went in depth on this specific problem from the book [here](https://www.zajichekstats.com/post/statistical-rethinking-2023-class-notes/#lecture2) which provides much more detail and code._</span>
<span id="cb35-279"><a href="#cb35-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-280"><a href="#cb35-280" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Notice that every updated set of plausibilities becomes the initial plausibilities for the next observation. Every conclusion is the starting point for future inference." (31)</span></span>
<span id="cb35-281"><a href="#cb35-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-282"><a href="#cb35-282" aria-hidden="true" tabindex="-1"></a>This supports the idea that our _model_ is the living, breathing thing, and that we should use everything we know up to _now_ to inform it. Then use new information to subsequently update it as time goes on. *Our model is never complete*.</span>
<span id="cb35-283"><a href="#cb35-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-284"><a href="#cb35-284" aria-hidden="true" tabindex="-1"></a>Another crucial point about considering sequential updates versus using your entire data set in a single updating step:</span>
<span id="cb35-285"><a href="#cb35-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-286"><a href="#cb35-286" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "So the data could be presented to your model in any order, or all at once even. In most cases, you will present the data all at once, for the sake of convenience. But it's important to realize that this merely represents abbreviation of an iterated learning process." (31)</span></span>
<span id="cb35-287"><a href="#cb35-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-288"><a href="#cb35-288" aria-hidden="true" tabindex="-1"></a>There is a catch though, as reflected later:</span>
<span id="cb35-289"><a href="#cb35-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-290"><a href="#cb35-290" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "That is only true, however, because the model assumes that order is irrelevant to inference. When something is irrelevant to the machine, it won't affect the inference directly. But it may affect it indirectly, because the data will depend upon order." (31)</span></span>
<span id="cb35-291"><a href="#cb35-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-292"><a href="#cb35-292" aria-hidden="true" tabindex="-1"></a>Hence the importance of _understanding_ the data-generating process.</span>
<span id="cb35-293"><a href="#cb35-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-294"><a href="#cb35-294" aria-hidden="true" tabindex="-1"></a><span class="fu">### Bayesian models need no data</span></span>
<span id="cb35-295"><a href="#cb35-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-296"><a href="#cb35-296" aria-hidden="true" tabindex="-1"></a>In the _Rethinking_ box on page 31, he discusses a crucial point related to what we've talked about: that there is no sample size requirement for Bayesian inference. This again is a _key_ reason why this paradigm is superior. We aren't stuck in asymptotics and arbitrary sample size cutoffs (e.g., N=30). We can specify our model, with prior information, using the best available knowledge we have up to this point in time, and actually get reliable estimates. Then as we collect a single observation, our new (posterior) estimates will nicely update to reflect the (likely little) amount of information contained in it, instead of needing to gather a bunch of data in order to get even get something interpretable. I previously discussed this in depth with an example here:</span>
<span id="cb35-297"><a href="#cb35-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-298"><a href="#cb35-298" aria-hidden="true" tabindex="-1"></a>{{&lt; video https://www.youtube.com/embed/bUerkVsCwtA &gt;}}</span>
<span id="cb35-299"><a href="#cb35-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-300"><a href="#cb35-300" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tie inferences back to what matters</span></span>
<span id="cb35-301"><a href="#cb35-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-302"><a href="#cb35-302" aria-hidden="true" tabindex="-1"></a>It's not enough to just provide an estimate and say "it matters" or not, like we arbitrarily do with frequentist p-values and 5% thresholds. These are empty statements. And again, for a result to be meaningful, we need to _feel it in our bones_. If all results were presented with such relevance, there wouldn't be so much controversy about the value of "science". This problem in large part in our society is due to the lacksidasical approach to assigning meaning to estimates, declaring scientific certainty, and not actually doing to the due diligence of acknowledging nuances to why some things matter to some people and some don't. </span>
<span id="cb35-303"><a href="#cb35-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-304"><a href="#cb35-304" aria-hidden="true" tabindex="-1"></a>This point is hit on in the _Evaluate_ section (2.2.3) of the book:</span>
<span id="cb35-305"><a href="#cb35-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-306"><a href="#cb35-306" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Instead, the objective is to check the model's adequacy for some purpose. This usually means asking and answering additional questions, beyond those that originally constructed the model. Both the questions and answers will depend upon the scientific context." (32)</span></span>
<span id="cb35-307"><a href="#cb35-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-308"><a href="#cb35-308" aria-hidden="true" tabindex="-1"></a>When we just blindly run statistical tests, get a p-value less than 5%, and then declare that "science shows this thing, and anyone who disregards it is anti-science", we've entered into something that is more religious, not scientific. Because we haven't actually convinced the person that these results matter. It is our job to frame scientific questions, their scope, and the subsequent results/interpretation closer something tangible that makes people _feel_ the results.</span>
<span id="cb35-309"><a href="#cb35-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-310"><a href="#cb35-310" aria-hidden="true" tabindex="-1"></a>As the great book <span class="co">[</span><span class="ot">The Cult of Statistical Significance: How the Standard Error Costs Us Jobs, Justice, and Lives</span><span class="co">](https://press.umich.edu/Books/T/The-Cult-of-Statistical-Significance2)</span> says:</span>
<span id="cb35-311"><a href="#cb35-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-312"><a href="#cb35-312" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Real science changes one’s mind. That’s one way to see that the proliferation of unpersuasive significance tests is not real science." (page 112)</span></span>
<span id="cb35-313"><a href="#cb35-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-314"><a href="#cb35-314" aria-hidden="true" tabindex="-1"></a>and </span>
<span id="cb35-315"><a href="#cb35-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-316"><a href="#cb35-316" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "She can test her belief in the price effect by looking at the magnitudes, using, for example, the highly advanced technique common in data-heavy articles in physics journals: ‘interocular trauma’. That is, she can look and see if the result hits her between the eyes." (page 72)</span></span>
<span id="cb35-317"><a href="#cb35-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-318"><a href="#cb35-318" aria-hidden="true" tabindex="-1"></a>See a much more extensive discussion of this book, and a large list of quotes from that book that I love, <span class="co">[</span><span class="ot">here</span><span class="co">](https://www.zajichekstats.com/post/statistical-significance-is-insignificant/)</span>.</span>
<span id="cb35-319"><a href="#cb35-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-320"><a href="#cb35-320" aria-hidden="true" tabindex="-1"></a><span class="fu">### Is Bayesian modeling subjective?</span></span>
<span id="cb35-321"><a href="#cb35-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-322"><a href="#cb35-322" aria-hidden="true" tabindex="-1"></a>A common critique of Bayesian modeling is that it is inherently subjective, because people choose their priors. I once thought of it that way as well, until I listed to <span class="co">[</span><span class="ot">this episode</span><span class="co">](https://learnbayesstats.com/episode/45-biostats-clinical-trial-design-frank-harrell)</span> of _Learning Bayesian Statistics_. Frank Harrell argues, and I now agree, that it is even less subjective because we are actually accounting for what we know, not just being forced into blind assumptions that occur in the frequentist paradigm. This is emphasized on page 35:</span>
<span id="cb35-323"><a href="#cb35-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-324"><a href="#cb35-324" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "None of this should be understood to mean that any statistical analysis is not inherently subjective, because of course it is--lots of little subjective decisions are involved in all parts of science. It's just that priors and Bayesian data analysis are no more inherently subjective than are likelihoods and the repeat sampling assumptions required for significance testing...No one is required to swear an oath to the assumptions of a model, and no set of assumptions deserves our obedience." (35)</span></span>
<span id="cb35-325"><a href="#cb35-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-326"><a href="#cb35-326" aria-hidden="true" tabindex="-1"></a><span class="fu">## Making Your Model Work</span></span>
<span id="cb35-327"><a href="#cb35-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-328"><a href="#cb35-328" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "However, knowing the mathematical rule is often of little help, because many of the interesting models in contemporary science cannot be conditioned formally, no matter your skill in mathematics. And while some broadly useful models like linear regression can be conditioned formally, this is only possible if you constrain your choice of prior to special forms that are easy to do mathematics with. We'd like to avoid forced modeling choices ot this kind, instead favoring conditioning engines that can accomodate whichever prior is most useful for inference" (39)</span></span>
<span id="cb35-329"><a href="#cb35-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-330"><a href="#cb35-330" aria-hidden="true" tabindex="-1"></a>One challenge in Bayesian analysis, and having the theoretical flexibility for specifying priors (and models in general) that best represent what you know, is that it doesn't always work out "nicely" mathematically. Most common statistical methods are used because the math works out, so we can have software that fits things according to that assumed structure. Similarly, in the Bayesian framework, for certain models, there are "nice" choices you can make for prior that make the posterior work out analytically (closed form solutions), which makes it easier to deal. </span>
<span id="cb35-331"><a href="#cb35-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-332"><a href="#cb35-332" aria-hidden="true" tabindex="-1"></a>But we don't necessarily want to restrict ourselves to choosing model structures and assumptions for the sake of mathematical convenience. We want to specify our models to reflect what we actually believe to be true. That means we may have very messy functions pulled out of our brain (e.g., step functions, weird shapes, etc.). But if that's what makes most sense scientifically, we want to have flexible estimating engines to allow us to do this and implement it. That's what motivates the need for things he talks about next, like _markov chain monte carlo (MCMC)_ simulation or quadratic approximation. These things let us focus on specifying models that we think make sense, regardless how the math plays out downstream. He calls these _conditioning engines_.</span>
<span id="cb35-333"><a href="#cb35-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-334"><a href="#cb35-334" aria-hidden="true" tabindex="-1"></a><span class="fu">### Grid approximation</span></span>
<span id="cb35-335"><a href="#cb35-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-336"><a href="#cb35-336" aria-hidden="true" tabindex="-1"></a>This is what we did <span class="co">[</span><span class="ot">above</span><span class="co">](#updatingpriors)</span>. We know that the true parameter value ($p$) could be anything (as it is continuous), but we approximated what the posterior would look like by chopping up its domain into small intervals and computing pseudo-discrete posteriors based on that. The yielding plots reflect _approximately_ what the actual posterior would look like if we derived the full analytical solution. I think this is a great way to do it, at least to start, because you can get into the "ballpark" of your posterior, and if for some reason that ends up not being specific enough to satisfy your inquiry, you can look to more complex methods to refine your estimates in a more complete way.</span>
<span id="cb35-337"><a href="#cb35-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-338"><a href="#cb35-338" aria-hidden="true" tabindex="-1"></a><span class="fu">### Quadratic approximation</span></span>
<span id="cb35-339"><a href="#cb35-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-340"><a href="#cb35-340" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Under quite general conditions, the region near the peak of the posterior distribution will be nearly Gaussian. This means the posterior distribution can be usefully approximated by a Gaussian distribution." (42)</span></span>
<span id="cb35-341"><a href="#cb35-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-342"><a href="#cb35-342" aria-hidden="true" tabindex="-1"></a>When we get more parameters in the model, we can't be specifying large grids of parameters to approximate, so we need something else. The quadratic approximation takes advantage of properties of posteriors (that, locally, they tend to be Gaussian), and that Gaussian distributions can be described by only the _mean_ and _variance_.</span>
<span id="cb35-343"><a href="#cb35-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-346"><a href="#cb35-346" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb35-347"><a href="#cb35-347" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rethinking)</span>
<span id="cb35-348"><a href="#cb35-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-349"><a href="#cb35-349" aria-hidden="true" tabindex="-1"></a>globe.pa <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb35-350"><a href="#cb35-350" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb35-351"><a href="#cb35-351" aria-hidden="true" tabindex="-1"></a>    W <span class="sc">~</span> <span class="fu">dbinom</span>(W<span class="sc">+</span>L, p),</span>
<span id="cb35-352"><a href="#cb35-352" aria-hidden="true" tabindex="-1"></a>    p <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb35-353"><a href="#cb35-353" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb35-354"><a href="#cb35-354" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> <span class="fu">list</span>(<span class="at">W =</span> <span class="dv">6</span>, <span class="at">L =</span> <span class="dv">3</span>)</span>
<span id="cb35-355"><a href="#cb35-355" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-356"><a href="#cb35-356" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(globe.pa)</span>
<span id="cb35-357"><a href="#cb35-357" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb35-358"><a href="#cb35-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-359"><a href="#cb35-359" aria-hidden="true" tabindex="-1"></a><span class="fu">### Markov chain Monte Carlo (MCMC)</span></span>
<span id="cb35-360"><a href="#cb35-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-361"><a href="#cb35-361" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "The conceptual challenge of MCMC lies in its highly non-obvious strategy. Instead of attempting to compute or approximate the posterior distribution directly, MCMC techniques merely draw samples from the posterior. You end up with a collection of parameter values, and the frequencies of these values correspond to the posterior plauibilities." (45)</span></span>
<span id="cb35-362"><a href="#cb35-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-363"><a href="#cb35-363" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span></span>
<span id="cb35-364"><a href="#cb35-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-365"><a href="#cb35-365" aria-hidden="true" tabindex="-1"></a>_Video Lecture From the Author_</span>
<span id="cb35-366"><a href="#cb35-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-367"><a href="#cb35-367" aria-hidden="true" tabindex="-1"></a>{{&lt; video https://www.youtube.com/embed/R1vcdhPBlXA &gt;}}</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/zajichek">
      <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/alexzajichek">
      <i class="bi bi-linkedin" role="img" aria-label="LinkedIn">
</i> 
    </a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>