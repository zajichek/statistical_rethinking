<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>1&nbsp; The Golem of Prague – A Journey Through Statistical Rethinking</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter2.html" rel="next">
<link href="./preface.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter1.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Golem of Prague</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">A Journey Through Statistical Rethinking</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter1.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Golem of Prague</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Small Worlds and Large Worlds</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#models-are-robots" id="toc-models-are-robots" class="nav-link active" data-scroll-target="#models-are-robots"><span class="header-section-number">1.1</span> Models are robots</a>
  <ul class="collapse">
  <li><a href="#good-to-play-in-everyones-yard" id="toc-good-to-play-in-everyones-yard" class="nav-link" data-scroll-target="#good-to-play-in-everyones-yard"><span class="header-section-number">1.1.1</span> Good to play in everyone’s yard?</a></li>
  </ul></li>
  <li><a href="#a-new-way-to-think" id="toc-a-new-way-to-think" class="nav-link" data-scroll-target="#a-new-way-to-think"><span class="header-section-number">1.2</span> A new way to think</a>
  <ul class="collapse">
  <li><a href="#flaws-in-falsifiability" id="toc-flaws-in-falsifiability" class="nav-link" data-scroll-target="#flaws-in-falsifiability"><span class="header-section-number">1.2.1</span> Flaws in falsifiability</a></li>
  </ul></li>
  <li><a href="#levels-of-hypotheses" id="toc-levels-of-hypotheses" class="nav-link" data-scroll-target="#levels-of-hypotheses"><span class="header-section-number">1.3</span> Levels of hypotheses</a>
  <ul class="collapse">
  <li><a href="#what-you-should-think-about" id="toc-what-you-should-think-about" class="nav-link" data-scroll-target="#what-you-should-think-about"><span class="header-section-number">1.3.1</span> What you should think about</a></li>
  </ul></li>
  <li><a href="#inching-towards-bayes-chapter1inching" id="toc-inching-towards-bayes-chapter1inching" class="nav-link" data-scroll-target="#inching-towards-bayes-chapter1inching"><span class="header-section-number">1.4</span> Inching towards Bayes {chapter1inching}</a>
  <ul class="collapse">
  <li><a href="#measuring-things" id="toc-measuring-things" class="nav-link" data-scroll-target="#measuring-things"><span class="header-section-number">1.4.1</span> Measuring things</a></li>
  </ul></li>
  <li><a href="#model-the-world" id="toc-model-the-world" class="nav-link" data-scroll-target="#model-the-world"><span class="header-section-number">1.5</span> Model the world</a></li>
  <li><a href="#the-tools-to-get-there" id="toc-the-tools-to-get-there" class="nav-link" data-scroll-target="#the-tools-to-get-there"><span class="header-section-number">1.6</span> The tools to get there</a>
  <ul class="collapse">
  <li><a href="#bayesian-vs.-frequentist" id="toc-bayesian-vs.-frequentist" class="nav-link" data-scroll-target="#bayesian-vs.-frequentist"><span class="header-section-number">1.6.1</span> Bayesian vs.&nbsp;frequentist</a></li>
  <li><a href="#bayesianing-not-bayesianism" id="toc-bayesianing-not-bayesianism" class="nav-link" data-scroll-target="#bayesianing-not-bayesianism"><span class="header-section-number">1.6.2</span> Bayesianing, not Bayesianism</a></li>
  </ul></li>
  <li><a href="#centering-the-model" id="toc-centering-the-model" class="nav-link" data-scroll-target="#centering-the-model"><span class="header-section-number">1.7</span> Centering the model</a>
  <ul class="collapse">
  <li><a href="#beyond-accuracy" id="toc-beyond-accuracy" class="nav-link" data-scroll-target="#beyond-accuracy"><span class="header-section-number">1.7.1</span> Beyond accuracy</a></li>
  <li><a href="#a-multilevel-approach" id="toc-a-multilevel-approach" class="nav-link" data-scroll-target="#a-multilevel-approach"><span class="header-section-number">1.7.2</span> A multilevel approach</a></li>
  </ul></li>
  <li><a href="#mechanism-and-causality" id="toc-mechanism-and-causality" class="nav-link" data-scroll-target="#mechanism-and-causality"><span class="header-section-number">1.8</span> Mechanism and causality</a>
  <ul class="collapse">
  <li><a href="#the-diagram" id="toc-the-diagram" class="nav-link" data-scroll-target="#the-diagram"><span class="header-section-number">1.8.1</span> The diagram</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Golem of Prague</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>“Animated by truth, but lacking free will, a golem always does exactly what it is told.” (1)</p>
</blockquote>
<section id="models-are-robots" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="models-are-robots"><span class="header-section-number">1.1</span> Models are robots</h2>
<p>Statistical models are (or can be) like <em>golems</em> in the sense that they are concerned with modeling the world (the truth), but they have no sense of morality on their own. They only do what is intended, regardless of consequences, implications, values, trade-offs, etc. It is up to <em>us</em> to direct the models towards what is useful, and use them in a way that makes sense–through logic, reasoning, common sense, etc. Therefore, we must separate the <em>mathematical</em> procedure of statistical modeling from the <em>interpretation</em> or implication that it has.</p>
<blockquote class="blockquote">
<p>“Sometimes their underlying logic reveals implications previously hidden to their designers. These implications can be priceless discoveries. Or they may produce silly and dangerous behavior…there is no wisdom in the golem. It doesn’t discern when the context is inappropriate for its answers. It just knows its own procedures, nothing else. It just does as it’s told.” (2)</p>
</blockquote>
<p>It’s often the case that statistics is taught straight from this <em>golem</em> point of view: people look at statistics as an objective, deterministic check list to do science. So they follow diagrams (like the test decision tree shown on page 2) to choose the “right” test, without considering any of the consequences of the golem that are only garnered through “wisdom”.</p>
<blockquote class="blockquote">
<p>“So students and many scientists tend to use charts like [the testing decision tree] without much thought to their underlying structure, without much awareness of the models that each procedure embodies, and without any framework to help them make the inevitable compromises required by real research. It’s not their fault.” (3)</p>
</blockquote>
<p>McElreath compares this to plumbers doing their jobs without knowing fluid dynamics, implying it can be “fine” in certain contexts. It’s when the user steps outside of the intended use by extrapolating: <em>“It’s as if we got out hydraulic engineers by promoting plumbers” (3)</em>. Now I get the point there, but I think there probably <em>is</em> inherent knowledge that plumbers could contribute to the hydraulic engineering process, which seems to be an afterthought here.</p>
<section id="good-to-play-in-everyones-yard" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="good-to-play-in-everyones-yard"><span class="header-section-number">1.1.1</span> Good to play in everyone’s yard?</h3>
<p>One common perk of statistics is that you can “play in everyone’s backyard”. It’s cool. But I’ve also <a href="https://www.zajichekstats.com/post/statistical-significance-is-insignificant/">more recently thought</a> this to be a somewhat negative thing for producing truly useful statistical results. McElreath hints at that here as well, first in describing the <em>inflexibility</em> and <em>fragility</em> of classical statistical methods and how they are used so frequently, yet are rarely <em>truly</em> appropriate. More pointedly, he makes the case:</p>
<blockquote class="blockquote">
<p>“The point is that classical tools are not diverse enough to handle many common research questions. Every active area of science contends with unique difficulties of measurement and interpretation, converses with idiosyncratic theories in a dialect barely understood by other scientists from other tribes. Statistical experts outside the discipline can help, but they are limited by lack of fluency in the empirical and theoretical concerns of the discipline.” (3)</p>
</blockquote>
<p>This is exactly right. Domain knowledge and intuition is king, and oftentimes statisticians (myself included) don’t truly have those things when approached for statistical assistance, limiting their ability to have <em>optimal</em> impact (though you may still be able to get the job done, if the goal is to say, just get a publication). I always say that a domain expert with some statistical chops is more effective than someone with tons of technical skills. That’s just the nature of it, so it’s about finding ways to collaborate with synergy to bring out what is needed from both sides.</p>
</section>
</section>
<section id="a-new-way-to-think" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="a-new-way-to-think"><span class="header-section-number">1.2</span> A new way to think</h2>
<p>He sets the stage for the book’s thesis quite clearly:</p>
<blockquote class="blockquote">
<p>“So there are benefits in rethinking statistical inference as a set of strategies, instead of a set of pre-made tools.” (4)</p>
</blockquote>
<p>It’s about statistical practice, of course, but also how we can <em>teach</em> statistics, even at an introductory level, differently so it’s not just based on objective, pre-made tools. This would be glorious. Instead of teaching students to systematically look up z-scores in the back of the text book and write out “significance” statements, teach them to solve problems with their brain. I’ve thought one simple way to start would just be to use varying (or random) confidence/significance levels on different problems, which at the very least would elicit some questioning and skepticism about what those numbers mean.</p>
<section id="flaws-in-falsifiability" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="flaws-in-falsifiability"><span class="header-section-number">1.2.1</span> Flaws in falsifiability</h3>
<p>He discusses Karl Popper and the perceived objective of science being to falsify hypotheses. I agree that in principle, this makes sense: there’s never really a right answer, but we can move closer and closer to the truth by finding evidence of what it’s not. But I think one thing that’s overlooked is how this plays out in the real-world (and what I deduce as an undertone from McElreath): null hypotheses that we test against are arbitrary and blindly applied. We test default hypotheses that we don’t even think ourselves to be true (i.e., null effects). It’s just part of the statistical procedure (on page 5 in the purple side box he actually goes into this explicitly). So I think this is a component of it, but he then goes more into other reasons why this is flawed.</p>
<ul>
<li><p><em>Hypotheses are not models</em>: Getting at the idea that somehow each hypothesis tested is somehow its own thing that move us in some direction. But these are often actually just different subcomponents of the same phenomenon. Considering a model of the world for something, the angles that it is studied at (e.g., by different researchers), what is actually tested, how things are measured, etc. There is so much varible overlap that it’s impossible to make any conclusive statements about that true <em>model</em> that we believe exists.</p></li>
<li><p><em>Measurement matters</em>: This is a huge point. <em>Our</em> study may suggest something. But you have a different group of people conduct the same study, there will be many nuances that likely differ. These things can always be critiqued, and cause real inconsistencies and variation–and rightly so. “They don’t trust the data. Sometimes they are right”. To me, this is one of the major flaws in current academic research when trying to confer individual implication to a study. There are literally infinite ways to conduct a study on the same topic.</p></li>
</ul>
<p>Models are always wrong, as he states, so how can we falsify one when we know whatever we choose next is wrong too? To me, this <em>is</em> a segway into Bayesian thinking. Instead of just looking at hypotheses in a traditional sense, we want to know what is <em>most likely</em> to have been the thing to created the data (out of all possibilities).</p>
<blockquote class="blockquote">
<p>“These hypotheses have vague boundries, because they begin as verbal conjectures, not precise models. There are hundreds of possible potential processes that [describe the null hypothesis].” (5)</p>
</blockquote>
</section>
</section>
<section id="levels-of-hypotheses" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="levels-of-hypotheses"><span class="header-section-number">1.3</span> Levels of hypotheses</h2>
<p>Digging further into the <em>hypotheses are not models</em> point, he describes layers to framing the model:</p>
<ol type="1">
<li>Hypotheses: These are the vague things stated above</li>
<li>Process models: These are more specific possibilities of actual data generating processes (and <em>causal</em> structure) that could fit into those vague bins. These are the conceptual, time dependent (i.e., cause-effect ordering), causal structures of what may explain a phenomenon.</li>
<li>Statistical models: We need to translate the causal model into some (associative) statistical model to be able to estimate things. The problem is that these models can be a result of multiple process models, even from different hypotheses.</li>
</ol>
<p>A key point here is that the <em>statistical model</em> (e.g., in this example) is what is represented by the statistical procedure/estimates, but that representation can be the same even with different data-generating processes, because the same data/predictions, for example, can be generated by completely different processes. Discussing typical hypothesis testing:</p>
<blockquote class="blockquote">
<p>“If we reject the null, we can’t really conclude that selection matters, because there are other neutral models that predict different distributions of alleles. And if we fail to reject the null, we can’t really conclude that evolution is neutral, because some selection models expect the same frequency distribution.” (7)</p>
</blockquote>
<section id="what-you-should-think-about" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="what-you-should-think-about"><span class="header-section-number">1.3.1</span> What you should think about</h3>
<blockquote class="blockquote">
<p>“If it turns out that all of the process models of interest make very similar predictions, then you know to search for a different description of the evidence, a description under which the processes look different.” (7)</p>
</blockquote>
<p>This means that the way we represent, estimate, or quantify the process then should be changed because the way you’re currently doing it leads to ambiguity. So find different metrics, different representations, etc. Also, focus on the data-generating process:</p>
<blockquote class="blockquote">
<p>“Process models allow us to design statistical models with [e.g., unobserved variables and sampling bias] in mind. The statistical model alone is not enough.” (7)</p>
</blockquote>
</section>
</section>
<section id="inching-towards-bayes-chapter1inching" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="inching-towards-bayes-chapter1inching"><span class="header-section-number">1.4</span> Inching towards Bayes {chapter1inching}</h2>
<p>The first part of section 1.2.2 (and everthing leading up to it) hints at a Bayesian point of view.</p>
<blockquote class="blockquote">
<p>“In contrast, finding D tells us nothing certain about H, because other hypotheses might also predict D.” (7)</p>
</blockquote>
<p>The idea is that many states of the world could very conceivably produce some observation, but that doesn’t mean that state of the world is therefore likely to be the one that did. This is very much related to the <em>fallacy of the transposed conditional</em> which I talk about here:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/-ZNh26oEPbg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>and is a central point to one of my favorite books, <a href="https://press.umich.edu/Books/T/The-Cult-of-Statistical-Significance2"><em>The Cult of Statistical Significance</em></a> and something I wrote about in a <a href="https://www.zajichekstats.com/post/statistical-significance-is-insignificant/">prior blog post</a>.</p>
<section id="measuring-things" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="measuring-things"><span class="header-section-number">1.4.1</span> Measuring things</h3>
<p>The <em>all swans are white</em> null example is useful as reference point to compare with other important scientific hypotheses we are truly after. In this case, with such a “big” statement (applying to ALL swans) you just need to see one black one and it’s over and done with. But the problem, at least in part, is:</p>
<ol type="a">
<li>Not all scientific inquiries are this simple, objective, and clear</li>
<li>Not all <em>measurements</em> about the thing are clear either.</li>
</ol>
<p>For example, what if the “black” swan you saw was actually a white swan that had a bad encounter with black paint or tar? Would you know? Maybe in that circumstance you would, but across all scientific inquiries, these nuances and possibilities for measurement error, bias, etc. are infinite.</p>
<blockquote class="blockquote">
<p>“At the edges of scientific knowledge, the ability to measure a hypothetical phenomenon is often in question as much as the phenomenon itself.” (8)</p>
</blockquote>
<p>The example about <a href="https://en.wikipedia.org/wiki/Neutrino">neutrinos</a> and the speed of light is a really great, intuitive example about the complexities and biases inherent to measurement. It’s people’s preconceived notion about what level of evidence is sufficient, mixed with the phenomenon being measured, the conditions under which it is being measured, and the fact that despite how “objective” we think a measurement device is, it is <em>always</em> an <em>estimate</em> of the real thing. Great section on page 8.</p>
<blockquote class="blockquote">
<p>“But the probabilistic nature of evidence rarely appears when practicing scientists discuss the philosophy and practice of falsification. My reading of the history of science is that these sorts of measurement problems are the norm, not the exception.” (9)</p>
</blockquote>
<p>In discussing more opaque hypotheses,</p>
<blockquote class="blockquote">
<p>“Now, nearly everyone agrees that it is a good practice to design experiments and observations that can differentiate competeing hypotheses. But in many cases, the comparison must be probabilistic, a matter of degree, not kind.” (9)</p>
</blockquote>
<p>Both of these hint at Bayesian thinking.</p>
<p>The last paragraph on in section 1.2 is very important:</p>
<blockquote class="blockquote">
<p>“But falsification is always consensual, not logical. In light of real problems of measurement error and the continuous nature of natural phenomena, scientific communities argue towards consensus about the meaning of evidence.” (9)</p>
</blockquote>
<p>It’s worth reading the rest of it. But the point being that we cannot objectively, and logical falsify something completely. It’s more so the consensus of people agree that, based on evidence, we all agree it is false. And the last sentence is key: <em>“And it may hurt the public, by exaggerating the definitiveness of scientific knowledge.”</em></p>
</section>
</section>
<section id="model-the-world" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="model-the-world"><span class="header-section-number">1.5</span> Model the world</h2>
<p>In order to take a new approach from falsification (and conform pre-existing golems to every situtation), we are to re-think everything in terms of models. Instead of applying a statistical test, we consider the model for how the data was generated–the data-generating process.</p>
<blockquote class="blockquote">
<p>“But if you are a good golem engineer, at least you’ll notice the destruction.” (10)</p>
</blockquote>
<p>The point of this quote is to say that by focusing on the <em>model</em>, you focus on mechanism. You aren’t using the golem (statistical test/model) as a brute force objective procedure to “apply” to your data, but rather tailor a unique golem for the specific purpose of answering your research question. Thus it has to do with constructing the right model, informed by common sense, domain knowledge, causal pathways, etc. so that the <em>interpretation</em> side (in which the golem doesn’t have) is better positioned to answer your question. This means you have to dig deeper than is traditionally done, because this is how true science <em>is</em> done. You have to think. You have to know your model. You have to reason. Nothing about this is about mechanistically just thoughtlessly throwing data into modeling software, getting a value, following some rule, and writing a blanket statement about the results. Basically, <em>you need to feel the result in your bones</em>.</p>
</section>
<section id="the-tools-to-get-there" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="the-tools-to-get-there"><span class="header-section-number">1.6</span> The tools to get there</h2>
<p>The book’s primary focus is causal modeling through Bayesian statistics. An important thing to note is that he doesn’t use Bayesian modeling for ideological reasons, per say, it’s more so that it just happens to be the framework that makes sense to facilitate modeling from a generative perspective.</p>
<section id="bayesian-vs.-frequentist" class="level3" data-number="1.6.1">
<h3 data-number="1.6.1" class="anchored" data-anchor-id="bayesian-vs.-frequentist"><span class="header-section-number">1.6.1</span> Bayesian vs.&nbsp;frequentist</h3>
<p>He simplifies Bayesian statistics as a way to count the ways things could happen, and then see what is most likely. And that’s a good way to think about it: we just want to know what is the most likely explanation for generating our observation, not how likely our data is under some hypothetical truth.</p>
<p>It’s also interesting he discusses <em>frequentist</em> statistics as a <em>special case</em> of Bayesian probability. He emphasizes that it’s based on the idea of imaginary resampling of data, and points out, and deservedly so, sure this could be a good way to think about it in a controlled lab experiment when you <em>could</em> conceivably keep sampling over and over, but for many other things, it just doesn’t make sense conceptually.</p>
<blockquote class="blockquote">
<p>“This resampling is never done, and in general it doesn’t even make sense–it is absurd to consider repeat sampling of the diversification of song birds in the Andes. As Sir Ronald Fisher, one of the most important frequentist statisticians of the twentieth century, put it: ‘the only populations that can be referred to in a test of significance have no objective reality, being exclusively the product of the statistician’s imagination.’” (11)</p>
</blockquote>
<p>Quite the interesting closing paragraph of page 11, stating that <em>“Bayesian golems treat ‘randomness’ as a property of information, not of the world.”</em></p>
<blockquote class="blockquote">
<p>“Nothing in the real world–excepting controversial interpretations of quantum physics–is actually random. Presumably, if we had more information, we could exactly predict everything. We just use randomness to describe our uncertainty in the face of incomplete knowledge. From the perspective of our golem, the coin toss is ‘random’, but it’s really the golem that is random, not the coin.” (11)</p>
</blockquote>
<p>He acknowledges the quantum point here. But that is precisely one of the main objections to the idea of “everything being predictable”. This is a potentially useful way to view a lot of things that are studied, because it makes a lot of sense, but probability fields in quantum physics seem to point to something deeper at a more fundamental level. This is explicitly discussed in the book, <a href="https://www.amazon.com/Light-Mind-World-Science-Illuminating/dp/1684515335"><em>Light of the Mind, Light of the World: Illuminating Science Through Faith</em></a>. It’s a central theme in the book, but Chapter 3 in particular discusses the “small gods” as being those who view the world from this mechanical philosophy: <em>“a conviction that the world was made of bodies, whose movements and collisions were as sharply regulated as those displayed by an intricately calibrated machine…if they could be described using numbers alone, atoms might reveal the truth underlying all things” (page 69)</em>.</p>
</section>
<section id="bayesianing-not-bayesianism" class="level3" data-number="1.6.2">
<h3 data-number="1.6.2" class="anchored" data-anchor-id="bayesianing-not-bayesianism"><span class="header-section-number">1.6.2</span> Bayesianing, not Bayesianism</h3>
<p>He further solidifies his stance that he’s not using Bayesian modeling on ideological grounds.</p>
<blockquote class="blockquote">
<p>“Note that the preceding description doesn’t invoke anyone’s ‘beliefs’ or subjective opinions. Bayesian data analysis is just a logical procedure for processing information. There is a tradition of using this procedure as a normative description of rational belief, a tradition called Bayesianism. But this book neither describes nor advocates it. In fact, I’ll argue that no statistical approach, Bayesian or otherwise, is by itself sufficient.” (12)</p>
</blockquote>
<p>He then goes on to describe the advantage of Bayesian analysis–it is more intuitive. People can grasp the practical implications easier, and it just makes sense. Otherwise you are just trying to remember some steps or criteria or what boilerplate sentence to write about a p-value, without actually thinking through what it means. The interesting case he makes it how often a p-value (or confidence interval) is interpreted like a <em>posterior probability</em> (<a href="chapter1inching">go back up the page</a>, this is related to the <em>fallacy of the transposed conditional</em> as well), but the reverse is not done.</p>
<blockquote class="blockquote">
<p>“The opposite pattern of mistake–interpreting a posterior probability as a p-value–seems to happen only rarely. None of this ensures Bayesian analysis will be more correct…the scientist’s intuition will less commonly be at odds with actual logic of the framework.” (12)</p>
</blockquote>
</section>
</section>
<section id="centering-the-model" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="centering-the-model"><span class="header-section-number">1.7</span> Centering the model</h2>
<p>As I’ve been learning about statistical history, philosophy, and Bayesian thinking, one huge differentiator I’ve realized is the basic idea that in the Bayesian setting, the <em>model</em> becomes the center of attention, and the <em>data</em> is just there to supplement it. To me, this changes the entire view of the problem. I’ve talked about this before, like in <a href="https://www.centralstatz.com/posts/can-you-have-a-model-without-data/">this blog post</a>, and in this supporting video:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/bUerkVsCwtA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>I bring this up because the first sentence of section 1.3.2, although stated casually, is very profound:</p>
<blockquote class="blockquote">
<p>“Bayesian data analysis provides a way for models to learn from data.” (13)</p>
</blockquote>
<p>The emphasis being that our <em>model</em> can learn from data. Meaning our <em>model</em> is a constant, a living, breathing object that describes the world. We only use data, as it comes and goes, to help inform that model as it is needed.</p>
<section id="beyond-accuracy" class="level3" data-number="1.7.1">
<h3 data-number="1.7.1" class="anchored" data-anchor-id="beyond-accuracy"><span class="header-section-number">1.7.1</span> Beyond accuracy</h3>
<p>He talks about the concept of overfitting, and the need for cross-validation, etc. But one attribute of Bayesian thinking that is related to this is the fact that multiple models can produce the same predictions, and so choosing the simpler one is in large part what Bayesian thinking does. So beyond getting good predictions, we’re chosen the model/mechanism that more likely generated the data. There is a <a href="https://nyaspubs.onlinelibrary.wiley.com/doi/10.1111/nyas.15086">fascinating paper</a> related to this topic that discusses how Bayesian modeling is essentially the realization of <a href="https://en.wikipedia.org/wiki/Occam%27s_razor">Occam’s Razor</a>–definitely worth the read.</p>
</section>
<section id="a-multilevel-approach" class="level3" data-number="1.7.2">
<h3 data-number="1.7.2" class="anchored" data-anchor-id="a-multilevel-approach"><span class="header-section-number">1.7.2</span> A multilevel approach</h3>
<p>He implicitly describes <em>multilevel models</em> as a key concept in this book. Yes, these are models that we think of: individual students in classrooms, classrooms in schools, schools in district, etc. But the <em>effect</em> of using these models is profound:</p>
<blockquote class="blockquote">
<p>“Cross-validation and information criteria measure overfitting risk and help us to recognize it. Multilevel models actually do something about it.” (14)</p>
</blockquote>
<p><em>Partial pooling</em> is what allows us to structure models and share information very it is necessary, while preserving variation and other important components of the data-generating process. In this sense, he extends this concept more generally to how we can think about multilevel modeling, in the context of missing data, factor analysis, etc. The concept that <em>“each parameter can be thought of as a placeholder for a missing model”</em> makes you realize the hierarchical structure of every modeling process.</p>
<p>He then makes a big claim: <em>“multilevel regression deserves to be the default form of regression”</em>. Stating that papers should have to justify <em>not</em> doing this, rather than the current practice. Intuitively, I think this makes sense. Part of the reason you can easily critique this in academic papers is because there are a lot of things worth critiquing, stemming from things like the cult of statistical significance, poor publication standards, reliance on “positive” p-values, and overall lack of accountability for anything that happens with the results beyond them being printed on a page, leaving open an infinite number of ways to “do” a study and get it published…but I digress.</p>
<blockquote class="blockquote">
<p>“Fitting and interpreting multilevel models can be considerably harder than fitting and interpreting a traditional regression model.” (15)</p>
</blockquote>
<p>Exactly. It’s harder. And there’s no incentive to do it, because they’ll still get the funding and publication, so same end result.</p>
</section>
</section>
<section id="mechanism-and-causality" class="level2" data-number="1.8">
<h2 data-number="1.8" class="anchored" data-anchor-id="mechanism-and-causality"><span class="header-section-number">1.8</span> Mechanism and causality</h2>
<blockquote class="blockquote">
<p>“Facts outside the data are needed to decide which explanation is correct.” (16)</p>
</blockquote>
<p>He makes a similar point here described above, that models can have similar predictions but not be the true causal mechanism. This has to do with overfitting (think the geocentric vs.&nbsp;heliocentric models), and inferring what makes sense logically regardless of the outputs of the model.</p>
<p>The concept of <em>identification</em> is very important here, because it distinguishes the simple act of predicting what will happen (i.e., I can <em>predict</em> that the wind is blowing given I see tree branches swaying) versus <em>intervening</em> on a process and inferring what will happen as a result (I can’t then go and move the branches around to make wind start blowing (besides the force generated from the branches which is different))</p>
<section id="the-diagram" class="level3" data-number="1.8.1">
<h3 data-number="1.8.1" class="anchored" data-anchor-id="the-diagram"><span class="header-section-number">1.8.1</span> The diagram</h3>
<p>We will use <em>directed acyclic graphs (DAG)</em> as the choice of <em>graphical causal model</em> (as this isn’t the only kind). They are not models themselves, but diagrams to help us think through what model and statistical procedures are most appropriate for the research question.</p>
<p>In the “Rethinking” box he makes the point about <em>causal salad</em>, which is just the idea that we can do causal inference by “adjusting for all confounders”, which is a very common practice in science, to just throw everything we can think of in a regression model and say we “controlled” for stuff. It’s curious why every one of those papers have a “limitation” section stating that causal inference can’t be assumed, like a disclaimer. Tells you that the people doing this probably don’t believe the results themselves, otherwise they’d be repressed to stand by such a statement.</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./preface.html" class="pagination-link" aria-label="Preface">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Preface</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter2.html" class="pagination-link" aria-label="Small Worlds and Large Worlds">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Small Worlds and Large Worlds</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># The Golem of Prague</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Animated by truth, but lacking free will, a golem always does exactly what it is told." (1)</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">## Models are robots</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>Statistical models are (or can be) like _golems_ in the sense that they are concerned with modeling the world (the truth), but they have no sense of morality on their own. They only do what is intended, regardless of consequences, implications, values, trade-offs, etc. It is up to _us_ to direct the models towards what is useful, and use them in a way that makes sense--through logic, reasoning, common sense, etc. Therefore, we must separate the _mathematical_ procedure of statistical modeling from the _interpretation_ or implication that it has.</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Sometimes their underlying logic reveals implications previously hidden to their designers. These implications can be priceless discoveries. Or they may produce silly and dangerous behavior...there is no wisdom in the golem. It doesn't discern when the context is inappropriate for its answers. It just knows its own procedures, nothing else. It just does as it's told." (2)</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>It's often the case that statistics is taught straight from this _golem_ point of view: people look at statistics as an objective, deterministic check list to do science. So they follow diagrams (like the test decision tree shown on page 2) to choose the "right" test, without considering any of the consequences of the golem that are only garnered through "wisdom". </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "So students and many scientists tend to use charts like </span><span class="co">[</span><span class="ot">the testing decision tree</span><span class="co">]</span><span class="at"> without much thought to their underlying structure, without much awareness of the models that each procedure embodies, and without any framework to help them make the inevitable compromises required by real research. It's not their fault." (3)</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>McElreath compares this to plumbers doing their jobs without knowing fluid dynamics, implying it can be "fine" in certain contexts. It's when the user steps outside of the intended use by extrapolating: _"It's as if we got out hydraulic engineers by promoting plumbers" (3)_. Now I get the point there, but I think there probably _is_ inherent knowledge that plumbers could contribute to the hydraulic engineering process, which seems to be an afterthought here.</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="fu">### Good to play in everyone's yard?</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>One common perk of statistics is that you can "play in everyone's backyard". It's cool. But I've also <span class="co">[</span><span class="ot">more recently thought</span><span class="co">](https://www.zajichekstats.com/post/statistical-significance-is-insignificant/)</span> this to be a somewhat negative thing for producing truly useful statistical results. McElreath hints at that here as well, first in describing the _inflexibility_ and _fragility_ of classical statistical methods and how they are used so frequently, yet are rarely _truly_ appropriate. More pointedly, he makes the case:</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "The point is that classical tools are not diverse enough to handle many common research questions. Every active area of science contends with unique difficulties of measurement and interpretation, converses with idiosyncratic theories in a dialect barely understood by other scientists from other tribes. Statistical experts outside the discipline can help, but they are limited by lack of fluency in the empirical and theoretical concerns of the discipline." (3)</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>This is exactly right. Domain knowledge and intuition is king, and oftentimes statisticians (myself included) don't truly have those things when approached for statistical assistance, limiting their ability to have _optimal_ impact (though you may still be able to get the job done, if the goal is to say, just get a publication). I always say that a domain expert with some statistical chops is more effective than someone with tons of technical skills. That's just the nature of it, so it's about finding ways to collaborate with synergy to bring out what is needed from both sides.</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="fu">## A new way to think</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>He sets the stage for the book's thesis quite clearly:</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "So there are benefits in rethinking statistical inference as a set of strategies, instead of a set of pre-made tools." (4)</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>It's about statistical practice, of course, but also how we can _teach_ statistics, even at an introductory level, differently so it's not just based on objective, pre-made tools. This would be glorious. Instead of teaching students to systematically look up z-scores in the back of the text book and write out "significance" statements, teach them to solve problems with their brain. I've thought one simple way to start would just be to use varying (or random) confidence/significance levels on different problems, which at the very least would elicit some questioning and skepticism about what those numbers mean.</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="fu">### Flaws in falsifiability</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>He discusses Karl Popper and the perceived objective of science being to falsify hypotheses. I agree that in principle, this makes sense: there's never really a right answer, but we can move closer and closer to the truth by finding evidence of what it's not. But I think one thing that's overlooked is how this plays out in the real-world (and what I deduce as an undertone from McElreath): null hypotheses that we test against are arbitrary and blindly applied. We test default hypotheses that we don't even think ourselves to be true (i.e., null effects). It's just part of the statistical procedure (on page 5 in the purple side box he actually goes into this explicitly). So I think this is a component of it, but he then goes more into other reasons why this is flawed.</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>_Hypotheses are not models_: Getting at the idea that somehow each hypothesis tested is somehow its own thing that move us in some direction. But these are often actually just different subcomponents of the same phenomenon. Considering a model of the world for something, the angles that it is studied at (e.g., by different researchers), what is actually tested, how things are measured, etc. There is so much varible overlap that it's impossible to make any conclusive statements about that true _model_ that we believe exists.</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>_Measurement matters_: This is a huge point. _Our_ study may suggest something. But you have a different group of people conduct the same study, there will be many nuances that likely differ. These things can always be critiqued, and cause real inconsistencies and variation--and rightly so. "They don't trust the data. Sometimes they are right". To me, this is one of the major flaws in current academic research when trying to confer individual implication to a study. There are literally infinite ways to conduct a study on the same topic.</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>Models are always wrong, as he states, so how can we falsify one when we know whatever we choose next is wrong too? To me, this _is_ a segway into Bayesian thinking. Instead of just looking at hypotheses in a traditional sense, we want to know what is _most likely_ to have been the thing to created the data (out of all possibilities).</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "These hypotheses have vague boundries, because they begin as verbal conjectures, not precise models. There are hundreds of possible potential processes that </span><span class="co">[</span><span class="ot">describe the null hypothesis</span><span class="co">]</span><span class="at">." (5)</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="fu">## Levels of hypotheses</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>Digging further into the _hypotheses are not models_ point, he describes layers to framing the model:</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Hypotheses: These are the vague things stated above</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Process models: These are more specific possibilities of actual data generating processes (and _causal_ structure) that could fit into those vague bins. These are the conceptual, time dependent (i.e., cause-effect ordering), causal structures of what may explain a phenomenon.</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Statistical models: We need to translate the causal model into some (associative) statistical model to be able to estimate things. The problem is that these models can be a result of multiple process models, even from different hypotheses.</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>A key point here is that the _statistical model_ (e.g., in this example) is what is represented by the statistical procedure/estimates, but that representation can be the same even with different data-generating processes, because the same data/predictions, for example, can be generated by completely different processes. Discussing typical hypothesis testing:</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "If we reject the null, we can't really conclude that selection matters, because there are other neutral models that predict different distributions of alleles. And if we fail to reject the null, we can't really conclude that evolution is neutral, because some selection models expect the same frequency distribution." (7)</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="fu">### What you should think about</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "If it turns out that all of the process models of interest make very similar predictions, then you know to search for a different description of the evidence, a description under which the processes look different." (7)</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>This means that the way we represent, estimate, or quantify the process then should be changed because the way you're currently doing it leads to ambiguity. So find different metrics, different representations, etc. Also, focus on the data-generating process:</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Process models allow us to design statistical models with </span><span class="co">[</span><span class="ot">e.g., unobserved variables and sampling bias</span><span class="co">]</span><span class="at"> in mind. The statistical model alone is not enough." (7)</span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="fu">## Inching towards Bayes {chapter1inching}</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>The first part of section 1.2.2 (and everthing leading up to it) hints at a Bayesian point of view. </span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "In contrast, finding D tells us nothing certain about H, because other hypotheses might also predict D." (7)</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>The idea is that many states of the world could very conceivably produce some observation, but that doesn't mean that state of the world is therefore likely to be the one that did. This is very much related to the _fallacy of the transposed conditional_ which I talk about here:</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>{{&lt; video https://www.youtube.com/embed/-ZNh26oEPbg &gt;}}</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>and is a central point to one of my favorite books, <span class="co">[</span><span class="ot">_The Cult of Statistical Significance_</span><span class="co">](https://press.umich.edu/Books/T/The-Cult-of-Statistical-Significance2)</span> and something I wrote about in a <span class="co">[</span><span class="ot">prior blog post</span><span class="co">](https://www.zajichekstats.com/post/statistical-significance-is-insignificant/)</span>.</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="fu">### Measuring things</span></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>The _all swans are white_ null example is useful as reference point to compare with other important scientific hypotheses we are truly after. In this case, with such a "big" statement (applying to ALL swans) you just need to see one black one and it's over and done with. But the problem, at least in part, is:</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>a. Not all scientific inquiries are this simple, objective, and clear</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>b. Not all _measurements_ about the thing are clear either.</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>For example, what if the "black" swan you saw was actually a white swan that had a bad encounter with black paint or tar? Would you know? Maybe in that circumstance you would, but across all scientific inquiries, these nuances and possibilities for measurement error, bias, etc. are infinite.</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "At the edges of scientific knowledge, the ability to measure a hypothetical phenomenon is often in question as much as the phenomenon itself." (8)</span></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>The example about <span class="co">[</span><span class="ot">neutrinos</span><span class="co">](https://en.wikipedia.org/wiki/Neutrino)</span> and the speed of light is a really great, intuitive example about the complexities and biases inherent to measurement. It's people's preconceived notion about what level of evidence is sufficient, mixed with the phenomenon being measured, the conditions under which it is being measured, and the fact that despite how "objective" we think a measurement device is, it is _always_ an _estimate_ of the real thing. Great section on page 8.</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "But the probabilistic nature of evidence rarely appears when practicing scientists discuss the philosophy and practice of falsification. My reading of the history of science is that these sorts of measurement problems are the norm, not the exception." (9)</span></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>In discussing more opaque hypotheses,</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Now, nearly everyone agrees that it is a good practice to design experiments and observations that can differentiate competeing hypotheses. But in many cases, the comparison must be probabilistic, a matter of degree, not kind." (9)</span></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>Both of these hint at Bayesian thinking.</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>The last paragraph on in section 1.2 is very important:</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "But falsification is always consensual, not logical. In light of real problems of measurement error and the continuous nature of natural phenomena, scientific communities argue towards consensus about the meaning of evidence." (9)</span></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>It's worth reading the rest of it. But the point being that we cannot objectively, and logical falsify something completely. It's more so the consensus of people agree that, based on evidence, we all agree it is false. And the last sentence is key: _"And it may hurt the public, by exaggerating the definitiveness of scientific knowledge."_</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model the world</span></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>In order to take a new approach from falsification (and conform pre-existing golems to every situtation), we are to re-think everything in terms of models. Instead of applying a statistical test, we consider the model for how the data was generated--the data-generating process.</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "But if you are a good golem engineer, at least you'll notice the destruction." (10)</span></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>The point of this quote is to say that by focusing on the _model_, you focus on mechanism. You aren't using the golem (statistical test/model) as a brute force objective procedure to "apply" to your data, but rather tailor a unique golem for the specific purpose of answering your research question. Thus it has to do with constructing the right model, informed by common sense, domain knowledge, causal pathways, etc. so that the _interpretation_ side (in which the golem doesn't have) is better positioned to answer your question. This means you have to dig deeper than is traditionally done, because this is how true science _is_ done. You have to think. You have to know your model. You have to reason. Nothing about this is about mechanistically just thoughtlessly throwing data into modeling software, getting a value, following some rule, and writing a blanket statement about the results. Basically, _you need to feel the result in your bones_.</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a><span class="fu">## The tools to get there</span></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>The book's primary focus is causal modeling through Bayesian statistics. An important thing to note is that he doesn't use Bayesian modeling for ideological reasons, per say, it's more so that it just happens to be the framework that makes sense to facilitate modeling from a generative perspective.</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="fu">### Bayesian vs. frequentist</span></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>He simplifies Bayesian statistics as a way to count the ways things could happen, and then see what is most likely. And that's a good way to think about it: we just want to know what is the most likely explanation for generating our observation, not how likely our data is under some hypothetical truth. </span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>It's also interesting he discusses _frequentist_ statistics as a _special case_ of Bayesian probability. He emphasizes that it's based on the idea of imaginary resampling of data, and points out, and deservedly so, sure this could be a good way to think about it in a controlled lab experiment when you _could_ conceivably keep sampling over and over, but for many other things, it just doesn't make sense conceptually. </span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "This resampling is never done, and in general it doesn't even make sense--it is absurd to consider repeat sampling of the diversification of song birds in the Andes. As Sir Ronald Fisher, one of the most important frequentist statisticians of the twentieth century, put it: 'the only populations that can be referred to in a test of significance have no objective reality, being exclusively the product of the statistician's imagination.'" (11)</span></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>Quite the interesting closing paragraph of page 11, stating that _"Bayesian golems treat 'randomness' as a property of information, not of the world."_ </span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Nothing in the real world--excepting controversial interpretations of quantum physics--is actually random. Presumably, if we had more information, we could exactly predict everything. We just use randomness to describe our uncertainty in the face of incomplete knowledge. From the perspective of our golem, the coin toss is 'random', but it's really the golem that is random, not the coin." (11)</span></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>He acknowledges the quantum point here. But that is precisely one of the main objections to the idea of "everything being predictable". This is a potentially useful way to view a lot of things that are studied, because it makes a lot of sense, but probability fields in quantum physics seem to point to something deeper at a more fundamental level. This is explicitly discussed in the book, <span class="co">[</span><span class="ot">_Light of the Mind, Light of the World: Illuminating Science Through Faith_</span><span class="co">](https://www.amazon.com/Light-Mind-World-Science-Illuminating/dp/1684515335)</span>. It's a central theme in the book, but Chapter 3 in particular discusses the "small gods" as being those who view the world from this mechanical philosophy: _"a conviction that the world was made of bodies, whose movements and collisions were as sharply regulated as those displayed by an intricately calibrated machine...if they could be described using numbers alone, atoms might reveal the truth underlying all things" (page 69)_.</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a><span class="fu">### Bayesianing, not Bayesianism</span></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>He further solidifies his stance that he's not using Bayesian modeling on ideological grounds.</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Note that the preceding description doesn't invoke anyone's 'beliefs' or subjective opinions. Bayesian data analysis is just a logical procedure for processing information. There is a tradition of using this procedure as a normative description of rational belief, a tradition called Bayesianism. But this book neither describes nor advocates it. In fact, I'll argue that no statistical approach, Bayesian or otherwise, is by itself sufficient." (12)</span></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>He then goes on to describe the advantage of Bayesian analysis--it is more intuitive. People can grasp the practical implications easier, and it just makes sense. Otherwise you are just trying to remember some steps or criteria or what boilerplate sentence to write about a p-value, without actually thinking through what it means. The interesting case he makes it how often a p-value (or confidence interval) is interpreted like a _posterior probability_ ([go back up the page](chapter1inching), this is related to the _fallacy of the transposed conditional_ as well), but the reverse is not done.</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "The opposite pattern of mistake--interpreting a posterior probability as a p-value--seems to happen only rarely. None of this ensures Bayesian analysis will be more correct...the scientist's intuition will less commonly be at odds with actual logic of the framework." (12)</span></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="fu">## Centering the model</span></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>As I've been learning about statistical history, philosophy, and Bayesian thinking, one huge differentiator I've realized is the basic idea that in the Bayesian setting, the _model_ becomes the center of attention, and the _data_ is just there to supplement it. To me, this changes the entire view of the problem. I've talked about this before, like in <span class="co">[</span><span class="ot">this blog post</span><span class="co">](https://www.centralstatz.com/posts/can-you-have-a-model-without-data/)</span>, and in this supporting video:</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>{{&lt; video https://www.youtube.com/embed/bUerkVsCwtA &gt;}}</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>I bring this up because the first sentence of section 1.3.2, although stated casually, is very profound:</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Bayesian data analysis provides a way for models to learn from data." (13)</span></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>The emphasis being that our _model_ can learn from data. Meaning our _model_ is a constant, a living, breathing object that describes the world. We only use data, as it comes and goes, to help inform that model as it is needed. </span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a><span class="fu">### Beyond accuracy</span></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>He talks about the concept of overfitting, and the need for cross-validation, etc. But one attribute of Bayesian thinking that is related to this is the fact that multiple models can produce the same predictions, and so choosing the simpler one is in large part what Bayesian thinking does. So beyond getting good predictions, we're chosen the model/mechanism that more likely generated the data. There is a <span class="co">[</span><span class="ot">fascinating paper</span><span class="co">](https://nyaspubs.onlinelibrary.wiley.com/doi/10.1111/nyas.15086)</span> related to this topic that discusses how Bayesian modeling is essentially the realization of <span class="co">[</span><span class="ot">Occam's Razor</span><span class="co">](https://en.wikipedia.org/wiki/Occam%27s_razor)</span>--definitely worth the read.</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a><span class="fu">### A multilevel approach</span></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>He implicitly describes _multilevel models_ as a key concept in this book. Yes, these are models that we think of: individual students in classrooms, classrooms in schools, schools in district, etc. But the _effect_ of using these models is profound:</span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Cross-validation and information criteria measure overfitting risk and help us to recognize it. Multilevel models actually do something about it." (14)</span></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>_Partial pooling_ is what allows us to structure models and share information very it is necessary, while preserving variation and other important components of the data-generating process. In this sense, he extends this concept more generally to how we can think about multilevel modeling, in the context of missing data, factor analysis, etc. The concept that _"each parameter can be thought of as a placeholder for a missing model"_ makes you realize the hierarchical structure of every modeling process.</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>He then makes a big claim: _"multilevel regression deserves to be the default form of regression"_. Stating that papers should have to justify _not_ doing this, rather than the current practice. Intuitively, I think this makes sense. Part of the reason you can easily critique this in academic papers is because there are a lot of things worth critiquing, stemming from things like the cult of statistical significance, poor publication standards, reliance on "positive" p-values, and overall lack of accountability for anything that happens with the results beyond them being printed on a page, leaving open an infinite number of ways to "do" a study and get it published...but I digress.</span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Fitting and interpreting multilevel models can be considerably harder than fitting and interpreting a traditional regression model." (15)</span></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>Exactly. It's harder. And there's no incentive to do it, because they'll still get the funding and publication, so same end result. </span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a><span class="fu">## Mechanism and causality</span></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "Facts outside the data are needed to decide which explanation is correct." (16)</span></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>He makes a similar point here described above, that models can have similar predictions but not be the true causal mechanism. This has to do with overfitting (think the geocentric vs. heliocentric models), and inferring what makes sense logically regardless of the outputs of the model.</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>The concept of _identification_ is very important here, because it distinguishes the simple act of predicting what will happen (i.e., I can _predict_ that the wind is blowing given I see tree branches swaying) versus _intervening_ on a process and inferring what will happen as a result (I can't then go and move the branches around to make wind start blowing (besides the force generated from the branches which is different))</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a><span class="fu">### The diagram</span></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a>We will use _directed acyclic graphs (DAG)_ as the choice of _graphical causal model_ (as this isn't the only kind). They are not models themselves, but diagrams to help us think through what model and statistical procedures are most appropriate for the research question.</span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a>In the "Rethinking" box he makes the point about _causal salad_, which is just the idea that we can do causal inference by "adjusting for all confounders", which is a very common practice in science, to just throw everything we can think of in a regression model and say we "controlled" for stuff. It's curious why every one of those papers have a "limitation" section stating that causal inference can't be assumed, like a disclaimer. Tells you that the people doing this probably don't believe the results themselves, otherwise they'd be repressed to stand by such a statement.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/zajichek">
      <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/alexzajichek">
      <i class="bi bi-linkedin" role="img" aria-label="LinkedIn">
</i> 
    </a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>