[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Journey Through Statistical Rethinking",
    "section": "",
    "text": "Introduction\nThis is a repository containing my exhaustive notes and code from my journey through Richard McElreath’s Statistical Rethinking (Second Edition). Each chapter corresponds to the chapter in the book.\nAll source code is available on GitHub in this repository. The book is deployed with GitHub Pages.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface",
    "section": "",
    "text": "Software Configuration\nGoing through the Preface, we need to do some preliminary configuration to prepare ourselves to use the software in the book. I’m running a 16 inch MacBook Pro (Nov 2023) Apple M3 Pro chip, and macOS Sonoma 14.6.1.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#software-configuration",
    "href": "preface.html#software-configuration",
    "title": "Preface",
    "section": "",
    "text": "Steps to get setup\nAs the book suggests:\n\n“You will need to install both a C++ compiler (also called a”tool chain”) and the rstan package. Instructions for doing both are at mc-stan.org\n\n\n1. Installing the C++ toolchain\nFrom the main web page, we go to the instructions for installing RStan.\n\na. Install macrtools\nWe can use this R package to help setup the C++ toolchain.\n\n# install.packages(\"remotes\")\nremotes::install_github(\"coatless-mac/macrtools\")\n\nThen we run the following command:\n\nmacrtools::macos_rtools_install()\n\nI was prompted to enter a password (my computer’s password) in RStudio. After it installed, I received this message in the R console:\nCongratulations! \nXcode CLI, Gfortran, and R developer binaries have been installed successfully.\n\n\nb. Optimize compiler\nWe run the R code here to “enable some compiler optimizations to improve the estimation speed of the model”:\n\ndotR &lt;- file.path(Sys.getenv(\"HOME\"), \".R\")\nif (!file.exists(dotR)) dir.create(dotR)\nM &lt;- file.path(dotR, \"Makevars\")\nif (!file.exists(M)) file.create(M)\narch &lt;- ifelse(R.version$arch == \"aarch64\", \"arm64\", \"x86_64\")\ncat(paste(\"\\nCXX17FLAGS += -O3 -mtune=native -arch\", arch, \"-ftemplate-depth-256\"),\n    file = M, sep = \"\\n\", append = FALSE)\n\nIt ran without error (though I don’t really know what it did).\n\n\n\n2. Install rstan\nGoing back to the RStan page, we can run the following installation:\n\ninstall.packages(\"rstan\", repos = \"https://cloud.r-project.org/\", dependencies = TRUE)\n\nThis worked.\n\nTest some examples\nRunning the following example:\n\nexample(stan_model, package = \"rstan\", run.dontrun = TRUE)\n\nI received a lot of output in the console (compilation and sampling).\n\nImport package\n\n## Load the package\nlibrary(\"rstan\") # observe startup messages\n\n# Set cores\noptions(mc.cores = parallel::detectCores()) # 12\n\n# Auto write compiled stan code\n# rstan_options(auto_write = TRUE) # &lt;-- Not doing it here, but would be useful\n\nIt says, “You will need to run these commands each time you load the rstan library.”\n\n\nRun an example model\nWe saved an example Stan file in stan/schools.stan, and then run the example:\n\n# Data to input into model\nschools_dat &lt;- \n  list(\n    J = 8, \n    y = c(28,  8, -3,  7, -1,  1, 18, 12),\n    sigma = c(15, 10, 16, 11,  9, 11, 10, 18)\n  )\n\n# Fit the model\nfit &lt;- stan(file = 'stan/schools.stan', data = schools_dat)\n\nIt fit with this message:\n\nWarning messages:\n1: There were 11 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them. \n2: Examine the pairs() plot to diagnose sampling problems\n\n\nprint(fit)\nplot(fit)\npairs(fit, pars = c(\"mu\", \"tau\", \"lp__\"))\n\nla &lt;- extract(fit, permuted = TRUE) # return a list of arrays \nmu &lt;- la$mu \n\n### return an array of three dimensions: iterations, chains, parameters \na &lt;- extract(fit, permuted = FALSE) \n\n### use S3 functions on stanfit objects\na2 &lt;- as.array(fit)\nm &lt;- as.matrix(fit)\nd &lt;- as.data.frame(fit)\n\n\n\n\n\nInstall book packages\n\ninstall.packages(c(\"coda\", \"mvtnorm\", \"devtools\", \"dagitty\"))\ndevtools::install_github(\"rmcelreath/rethinking\")\n\nHad issues with cmdstanr, so I’m following instructions here.\n\n# we recommend running this is a fresh R session or restarting your current session\ninstall.packages(\"cmdstanr\", repos = c('https://stan-dev.r-universe.dev', getOption(\"repos\")))\n\nNow try again\n\ndevtools::install_github(\"rmcelreath/rethinking\")\n\nSuccess!\nAt this point, I don’t know what is better: rstan or cmdstanr",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "1  The Golem of Prague",
    "section": "",
    "text": "1.1 Models are robots\nStatistical models are (or can be) like golems in the sense that they are concerned with modeling the world (the truth), but they have no sense of morality on their own. They only do what is intended, regardless of consequences, implications, values, trade-offs, etc. It is up to us to direct the models towards what is useful, and use them in a way that makes sense–through logic, reasoning, common sense, etc. Therefore, we must separate the mathematical procedure of statistical modeling from the interpretation or implication that it has.\nIt’s often the case that statistics is taught straight from this golem point of view: people look at statistics as an objective, deterministic check list to do science. So they follow diagrams (like the test decision tree shown on page 2) to choose the “right” test, without considering any of the consequences of the golem that are only garnered through “wisdom”.\nMcElreath compares this to plumbers doing their jobs without knowing fluid dynamics, implying it can be “fine” in certain contexts. It’s when the user steps outside of the intended use by extrapolating: “It’s as if we got out hydraulic engineers by promoting plumbers” (3). Now I get the point there, but I think there probably is inherent knowledge that plumbers could contribute to the hydraulic engineering process, which seems to be an afterthought here.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Golem of Prague</span>"
    ]
  },
  {
    "objectID": "chapter1.html#models-are-robots",
    "href": "chapter1.html#models-are-robots",
    "title": "1  The Golem of Prague",
    "section": "",
    "text": "“Sometimes their underlying logic reveals implications previously hidden to their designers. These implications can be priceless discoveries. Or they may produce silly and dangerous behavior…there is no wisdom in the golem. It doesn’t discern when the context is inappropriate for its answers. It just knows its own procedures, nothing else. It just does as it’s told.” (2)\n\n\n\n“So students and many scientists tend to use charts like [the testing decision tree] without much thought to their underlying structure, without much awareness of the models that each procedure embodies, and without any framework to help them make the inevitable compromises required by real research. It’s not their fault.” (3)\n\n\n\n1.1.1 Good to play in everyone’s yard?\nOne common perk of statistics is that you can “play in everyone’s backyard”. It’s cool. But I’ve also more recently thought this to be a somewhat negative thing for producing truly useful statistical results. McElreath hints at that here as well, first in describing the inflexibility and fragility of classical statistical methods and how they are used so frequently, yet are rarely truly appropriate. More pointedly, he makes the case:\n\n“The point is that classical tools are not diverse enough to handle many common research questions. Every active area of science contends with unique difficulties of measurement and interpretation, converses with idiosyncratic theories in a dialect barely understood by other scientists from other tribes. Statistical experts outside the discipline can help, but they are limited by lack of fluency in the empirical and theoretical concerns of the discipline.” (3)\n\nThis is exactly right. Domain knowledge and intuition is king, and oftentimes statisticians (myself included) don’t truly have those things when approached for statistical assistance, limiting their ability to have optimal impact (though you may still be able to get the job done, if the goal is to say, just get a publication). I always say that a domain expert with some statistical chops is more effective than someone with tons of technical skills. That’s just the nature of it, so it’s about finding ways to collaborate with synergy to bring out what is needed from both sides.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Golem of Prague</span>"
    ]
  },
  {
    "objectID": "chapter1.html#a-new-way-to-think",
    "href": "chapter1.html#a-new-way-to-think",
    "title": "1  The Golem of Prague",
    "section": "1.2 A new way to think",
    "text": "1.2 A new way to think\nHe sets the stage for the book’s thesis quite clearly:\n\n“So there are benefits in rethinking statistical inference as a set of strategies, instead of a set of pre-made tools.” (4)\n\nIt’s about statistical practice, of course, but also how we can teach statistics, even at an introductory level, differently so it’s not just based on objective, pre-made tools. This would be glorious. Instead of teaching students to systematically look up z-scores in the back of the text book and write out “significance” statements, teach them to solve problems with their brain. I’ve thought one simple way to start would just be to use varying (or random) confidence/significance levels on different problems, which at the very least would elicit some questioning and skepticism about what those numbers mean.\n\n1.2.1 Flaws in falsifiability\nHe discusses Karl Popper and the perceived objective of science being to falsify hypotheses. I agree that in principle, this makes sense: there’s never really a right answer, but we can move closer and closer to the truth by finding evidence of what it’s not. But I think one thing that’s overlooked is how this plays out in the real-world (and what I deduce as an undertone from McElreath): null hypotheses that we test against are arbitrary and blindly applied. We test default hypotheses that we don’t even think ourselves to be true (i.e., null effects). It’s just part of the statistical procedure (on page 5 in the purple side box he actually goes into this explicitly). So I think this is a component of it, but he then goes more into other reasons why this is flawed.\n\nHypotheses are not models: Getting at the idea that somehow each hypothesis tested is somehow its own thing that move us in some direction. But these are often actually just different subcomponents of the same phenomenon. Considering a model of the world for something, the angles that it is studied at (e.g., by different researchers), what is actually tested, how things are measured, etc. There is so much varible overlap that it’s impossible to make any conclusive statements about that true model that we believe exists.\nMeasurement matters: This is a huge point. Our study may suggest something. But you have a different group of people conduct the same study, there will be many nuances that likely differ. These things can always be critiqued, and cause real inconsistencies and variation–and rightly so. “They don’t trust the data. Sometimes they are right”. To me, this is one of the major flaws in current academic research when trying to confer individual implication to a study. There are literally infinite ways to conduct a study on the same topic.\n\nModels are always wrong, as he states, so how can we falsify one when we know whatever we choose next is wrong too? To me, this is a segway into Bayesian thinking. Instead of just looking at hypotheses in a traditional sense, we want to know what is most likely to have been the thing to created the data (out of all possibilities).\n\n“These hypotheses have vague boundries, because they begin as verbal conjectures, not precise models. There are hundreds of possible potential processes that [describe the null hypothesis].” (5)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Golem of Prague</span>"
    ]
  },
  {
    "objectID": "chapter1.html#levels-of-hypotheses",
    "href": "chapter1.html#levels-of-hypotheses",
    "title": "1  The Golem of Prague",
    "section": "1.3 Levels of hypotheses",
    "text": "1.3 Levels of hypotheses\nDigging further into the hypotheses are not models point, he describes layers to framing the model:\n\nHypotheses: These are the vague things stated above\nProcess models: These are more specific possibilities of actual data generating processes (and causal structure) that could fit into those vague bins. These are the conceptual, time dependent (i.e., cause-effect ordering), causal structures of what may explain a phenomenon.\nStatistical models: We need to translate the causal model into some (associative) statistical model to be able to estimate things. The problem is that these models can be a result of multiple process models, even from different hypotheses.\n\nA key point here is that the statistical model (e.g., in this example) is what is represented by the statistical procedure/estimates, but that representation can be the same even with different data-generating processes, because the same data/predictions, for example, can be generated by completely different processes. Discussing typical hypothesis testing:\n\n“If we reject the null, we can’t really conclude that selection matters, because there are other neutral models that predict different distributions of alleles. And if we fail to reject the null, we can’t really conclude that evolution is neutral, because some selection models expect the same frequency distribution.” (7)\n\n\n1.3.1 What you should think about\n\n“If it turns out that all of the process models of interest make very similar predictions, then you know to search for a different description of the evidence, a description under which the processes look different.” (7)\n\nThis means that the way we represent, estimate, or quantify the process then should be changed because the way you’re currently doing it leads to ambiguity. So find different metrics, different representations, etc. Also, focus on the data-generating process:\n\n“Process models allow us to design statistical models with [e.g., unobserved variables and sampling bias] in mind. The statistical model alone is not enough.” (7)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Golem of Prague</span>"
    ]
  },
  {
    "objectID": "chapter1.html#inching-towards-bayes",
    "href": "chapter1.html#inching-towards-bayes",
    "title": "1  The Golem of Prague",
    "section": "1.4 Inching towards Bayes",
    "text": "1.4 Inching towards Bayes\nThe first part of section 1.2.2 (and everthing leading up to it) hints at a Bayesian point of view.\n\n“In contrast, finding D tells us nothing certain about H, because other hypotheses might also predict D.” (7)\n\nThe idea is that many states of the world could very conceivably produce some observation, but that doesn’t mean that state of the world is therefore likely to be the one that did. This is very much related to the fallacy of the transposed conditional which I talk about here:\n\nand is a central point to one of my favorite books, The Cult of Statistical Significance and something I wrote about in a prior blog post.\n\n1.4.1 Measuring things\nThe all swans are white null example is useful as reference point to compare with other important scientific hypotheses we are truly after. In this case, with such a “big” statement (applying to ALL swans) you just need to see one black one and it’s over and done with. But the problem, at least in part, is:\n\nNot all scientific inquiries are this simple, objective, and clear\nNot all measurements about the thing are clear either.\n\nFor example, what if the “black” swan you saw was actually a white swan that had a bad encounter with black paint or tar? Would you know? Maybe in that circumstance you would, but across all scientific inquiries, these nuances and possibilities for measurement error, bias, etc. are infinite.\n\n“At the edges of scientific knowledge, the ability to measure a hypothetical phenomenon is often in question as much as the phenomenon itself.” (8)\n\nThe example about neutrinos and the speed of light is a really great, intuitive example about the complexities and biases inherent to measurement. It’s people’s preconceived notion about what level of evidence is sufficient, mixed with the phenomenon being measured, the conditions under which it is being measured, and the fact that despite how “objective” we think a measurement device is, it is always an estimate of the real thing. Great section on page 8.\n\n“But the probabilistic nature of evidence rarely appears when practicing scientists discuss the philosophy and practice of falsification. My reading of the history of science is that these sorts of measurement problems are the norm, not the exception.” (9)\n\nIn discussing more opaque hypotheses,\n\n“Now, nearly everyone agrees that it is a good practice to design experiments and observations that can differentiate competeing hypotheses. But in many cases, the comparison must be probabilistic, a matter of degree, not kind.” (9)\n\nBoth of these hint at Bayesian thinking.\nThe last paragraph on in section 1.2 is very important:\n\n“But falsification is always consensual, not logical. In light of real problems of measurement error and the continuous nature of natural phenomena, scientific communities argue towards consensus about the meaning of evidence.” (9)\n\nIt’s worth reading the rest of it. But the point being that we cannot objectively, and logical falsify something completely. It’s more so the consensus of people agree that, based on evidence, we all agree it is false. And the last sentence is key: “And it may hurt the public, by exaggerating the definitiveness of scientific knowledge.”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Golem of Prague</span>"
    ]
  }
]